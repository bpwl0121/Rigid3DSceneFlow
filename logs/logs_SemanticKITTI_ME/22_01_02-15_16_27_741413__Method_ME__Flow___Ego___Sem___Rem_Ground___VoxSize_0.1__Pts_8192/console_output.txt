2022-01-02 15:16:27,742 [INFO] root - Command: train.py ./configs/train/train_weakly_supervised.yaml
2022-01-02 15:16:27,743 [INFO] root - Arguments: method_backbone: ME, method_flow: True, method_ego_motion: True, method_semantic: True, method_clustering: True, method_loop_ego: True, method_loop_flow: True, method_umeyama: False, misc_voxel_size: 0.1, misc_num_points: 8192, misc_trainer: FlowTrainer, misc_use_gpu: True, misc_log_dir: ./logs/, misc_run_mode: train, data_input_features: absolute_coords, data_only_near_points: True, data_dataset: SemanticKITTI_ME, data_root: ./data/semantic_kitti/, data_n_classes: 2, data_remove_ground: True, data_augment_data: True, train_batch_size: 6, train_acc_iter_size: 1, train_num_workers: 6, train_max_epoch: 39, train_stat_interval: 20, train_chkpt_interval: -1, train_val_interval: -1, train_weighted_seg_loss: True, val_batch_size: 6, val_num_workers: 6, test_results_dir: ./eval/, test_batch_size: 1, test_num_workers: 1, loss_bg_loss_w: 1.0, loss_fg_loss_w: 1.0, loss_flow_loss_w: 1.0, loss_ego_loss_w: 1.0, loss_inlier_loss_w: 0.005, loss_cd_loss_w: 0.5, loss_rigid_loss_w: 1.0, loss_background_loss: True, loss_flow_loss: False, loss_ego_loss: True, loss_foreground_loss: True, optimizer_alg: Adam, optimizer_learning_rate: 0.001, optimizer_weight_decay: 0.0, optimizer_momentum: 0.8, optimizer_scheduler: ExponentialLR, optimizer_exp_gamma: 0.98, network_normalize_features: True, network_norm_type: IN, network_in_kernel_size: 7, network_feature_dim: 64, network_ego_motion_points: 1024, network_add_slack: True, network_sinkhorn_iter: 3, network_use_pretrained: True, network_cluster_metric: euclidean, network_min_p_cluster: 30, network_min_samples_dbscan: 5, network_eps_dbscan: 0.75, network_pretrained_path: , metrics_flow: False, metrics_ego_motion: True, metrics_semantic: True
2022-01-02 15:16:27,743 [INFO] root - Output and logs will be saved to ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192
2022-01-02 15:16:27,745 [INFO] root - Parameter Count: 8078149
2022-01-02 15:16:27,745 [INFO] root - Torch version: 1.7.1+cu110
2022-01-02 15:16:27,745 [INFO] root - CUDA version: 11.0
2022-01-02 15:16:27,752 [INFO] root - Training epoch: 0, LR: [0.001] 
2022-01-02 15:17:22,367 [INFO] root - Epoch 0 - It. 19: loss = 1.531
2022-01-02 15:18:15,086 [INFO] root - Epoch 0 - It. 39: loss = 1.319
2022-01-02 15:19:09,156 [INFO] root - Epoch 0 - It. 59: loss = 1.256
2022-01-02 15:20:03,283 [INFO] root - Epoch 0 - It. 79: loss = 1.178
2022-01-02 15:20:57,679 [INFO] root - Epoch 0 - It. 99: loss = 1.121
2022-01-02 15:21:50,138 [INFO] root - Epoch 0 - It. 119: loss = 1.026
2022-01-02 15:22:43,550 [INFO] root - Epoch 0 - It. 139: loss = 0.941
2022-01-02 15:23:29,674 [INFO] root - Starting the validation
2022-01-02 15:24:21,323 [INFO] root - VALIDATION -It. 156: total loss: 0.825.
2022-01-02 15:24:21,324 [INFO] root - New best model (loss: 0.8246)
2022-01-02 15:24:21,325 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 15:24:21,490 [INFO] root - Training epoch: 1, LR: [0.00098] 
2022-01-02 15:24:30,523 [INFO] root - Epoch 1 - It. 159: loss = 0.903
2022-01-02 15:25:24,781 [INFO] root - Epoch 1 - It. 179: loss = 0.841
2022-01-02 15:26:19,242 [INFO] root - Epoch 1 - It. 199: loss = 0.767
2022-01-02 15:27:12,747 [INFO] root - Epoch 1 - It. 219: loss = 0.753
2022-01-02 15:28:06,657 [INFO] root - Epoch 1 - It. 239: loss = 0.755
2022-01-02 15:29:00,796 [INFO] root - Epoch 1 - It. 259: loss = 0.749
2022-01-02 15:29:53,846 [INFO] root - Epoch 1 - It. 279: loss = 0.712
2022-01-02 15:30:46,336 [INFO] root - Epoch 1 - It. 299: loss = 0.721
2022-01-02 15:31:23,896 [INFO] root - Starting the validation
2022-01-02 15:32:15,298 [INFO] root - VALIDATION -It. 313: total loss: 0.630.
2022-01-02 15:32:15,299 [INFO] root - New best model (loss: 0.6296)
2022-01-02 15:32:15,300 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 15:32:15,779 [INFO] root - Training epoch: 2, LR: [0.0009603999999999999] 
2022-01-02 15:32:32,552 [INFO] root - Epoch 2 - It. 319: loss = 0.671
2022-01-02 15:33:26,617 [INFO] root - Epoch 2 - It. 339: loss = 0.644
2022-01-02 15:34:20,883 [INFO] root - Epoch 2 - It. 359: loss = 0.653
2022-01-02 15:35:16,010 [INFO] root - Epoch 2 - It. 379: loss = 0.638
2022-01-02 15:36:09,166 [INFO] root - Epoch 2 - It. 399: loss = 0.636
2022-01-02 15:37:02,706 [INFO] root - Epoch 2 - It. 419: loss = 0.629
2022-01-02 15:37:57,061 [INFO] root - Epoch 2 - It. 439: loss = 0.583
2022-01-02 15:38:49,930 [INFO] root - Epoch 2 - It. 459: loss = 0.603
2022-01-02 15:39:19,067 [INFO] root - Starting the validation
2022-01-02 15:40:10,698 [INFO] root - VALIDATION -It. 470: total loss: 0.573.
2022-01-02 15:40:10,699 [INFO] root - New best model (loss: 0.5732)
2022-01-02 15:40:10,700 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 15:40:11,157 [INFO] root - Training epoch: 3, LR: [0.0009411919999999999] 
2022-01-02 15:40:36,067 [INFO] root - Epoch 3 - It. 479: loss = 0.626
2022-01-02 15:41:31,034 [INFO] root - Epoch 3 - It. 499: loss = 0.550
2022-01-02 15:42:24,509 [INFO] root - Epoch 3 - It. 519: loss = 0.570
2022-01-02 15:43:18,187 [INFO] root - Epoch 3 - It. 539: loss = 0.575
2022-01-02 15:44:11,627 [INFO] root - Epoch 3 - It. 559: loss = 0.574
2022-01-02 15:45:05,967 [INFO] root - Epoch 3 - It. 579: loss = 0.590
2022-01-02 15:45:59,773 [INFO] root - Epoch 3 - It. 599: loss = 0.541
2022-01-02 15:46:53,178 [INFO] root - Epoch 3 - It. 619: loss = 0.543
2022-01-02 15:47:14,647 [INFO] root - Starting the validation
2022-01-02 15:48:06,316 [INFO] root - VALIDATION -It. 627: total loss: 0.519.
2022-01-02 15:48:06,317 [INFO] root - New best model (loss: 0.5189)
2022-01-02 15:48:06,318 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 15:48:06,797 [INFO] root - Training epoch: 4, LR: [0.0009223681599999998] 
2022-01-02 15:48:40,059 [INFO] root - Epoch 4 - It. 639: loss = 0.537
2022-01-02 15:49:33,811 [INFO] root - Epoch 4 - It. 659: loss = 0.552
2022-01-02 15:50:27,572 [INFO] root - Epoch 4 - It. 679: loss = 0.508
2022-01-02 15:51:21,037 [INFO] root - Epoch 4 - It. 699: loss = 0.545
2022-01-02 15:52:15,438 [INFO] root - Epoch 4 - It. 719: loss = 0.573
2022-01-02 15:53:08,937 [INFO] root - Epoch 4 - It. 739: loss = 0.526
2022-01-02 15:54:02,593 [INFO] root - Epoch 4 - It. 759: loss = 0.496
2022-01-02 15:54:56,283 [INFO] root - Epoch 4 - It. 779: loss = 0.504
2022-01-02 15:55:09,865 [INFO] root - Starting the validation
2022-01-02 15:56:01,623 [INFO] root - VALIDATION -It. 784: total loss: 0.495.
2022-01-02 15:56:01,624 [INFO] root - New best model (loss: 0.4946)
2022-01-02 15:56:01,625 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 15:56:02,112 [INFO] root - Training epoch: 5, LR: [0.0009039207967999998] 
2022-01-02 15:56:43,244 [INFO] root - Epoch 5 - It. 799: loss = 0.485
2022-01-02 15:57:36,432 [INFO] root - Epoch 5 - It. 819: loss = 0.507
2022-01-02 15:58:31,346 [INFO] root - Epoch 5 - It. 839: loss = 0.491
2022-01-02 15:59:24,401 [INFO] root - Epoch 5 - It. 859: loss = 0.488
2022-01-02 16:00:18,581 [INFO] root - Epoch 5 - It. 879: loss = 0.489
2022-01-02 16:01:11,665 [INFO] root - Epoch 5 - It. 899: loss = 0.493
2022-01-02 16:02:05,014 [INFO] root - Epoch 5 - It. 919: loss = 0.509
2022-01-02 16:02:58,182 [INFO] root - Epoch 5 - It. 939: loss = 0.501
2022-01-02 16:03:03,677 [INFO] root - Starting the validation
2022-01-02 16:03:55,720 [INFO] root - VALIDATION -It. 941: total loss: 0.515.
2022-01-02 16:03:55,722 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_941.pt ...
2022-01-02 16:03:55,885 [INFO] root - Training epoch: 6, LR: [0.0008858423808639998] 
2022-01-02 16:04:44,683 [INFO] root - Epoch 6 - It. 959: loss = 0.506
2022-01-02 16:05:38,527 [INFO] root - Epoch 6 - It. 979: loss = 0.503
2022-01-02 16:06:32,748 [INFO] root - Epoch 6 - It. 999: loss = 0.472
2022-01-02 16:07:27,198 [INFO] root - Epoch 6 - It. 1019: loss = 0.435
2022-01-02 16:08:20,283 [INFO] root - Epoch 6 - It. 1039: loss = 0.501
2022-01-02 16:09:13,967 [INFO] root - Epoch 6 - It. 1059: loss = 0.458
2022-01-02 16:10:07,387 [INFO] root - Epoch 6 - It. 1079: loss = 0.466
2022-01-02 16:10:58,349 [INFO] root - Starting the validation
2022-01-02 16:11:50,268 [INFO] root - VALIDATION -It. 1098: total loss: 0.465.
2022-01-02 16:11:50,269 [INFO] root - New best model (loss: 0.4652)
2022-01-02 16:11:50,271 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:11:50,728 [INFO] root - Training epoch: 7, LR: [0.0008681255332467198] 
2022-01-02 16:11:54,569 [INFO] root - Epoch 7 - It. 1099: loss = 0.503
2022-01-02 16:12:47,419 [INFO] root - Epoch 7 - It. 1119: loss = 0.482
2022-01-02 16:13:41,202 [INFO] root - Epoch 7 - It. 1139: loss = 0.457
2022-01-02 16:14:35,456 [INFO] root - Epoch 7 - It. 1159: loss = 0.434
2022-01-02 16:15:29,016 [INFO] root - Epoch 7 - It. 1179: loss = 0.448
2022-01-02 16:16:22,816 [INFO] root - Epoch 7 - It. 1199: loss = 0.473
2022-01-02 16:17:15,910 [INFO] root - Epoch 7 - It. 1219: loss = 0.474
2022-01-02 16:18:09,689 [INFO] root - Epoch 7 - It. 1239: loss = 0.443
2022-01-02 16:18:52,481 [INFO] root - Starting the validation
2022-01-02 16:19:44,023 [INFO] root - VALIDATION -It. 1255: total loss: 0.455.
2022-01-02 16:19:44,024 [INFO] root - New best model (loss: 0.4550)
2022-01-02 16:19:44,025 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:19:44,479 [INFO] root - Training epoch: 8, LR: [0.0008507630225817853] 
2022-01-02 16:19:56,203 [INFO] root - Epoch 8 - It. 1259: loss = 0.440
2022-01-02 16:20:50,543 [INFO] root - Epoch 8 - It. 1279: loss = 0.447
2022-01-02 16:21:44,043 [INFO] root - Epoch 8 - It. 1299: loss = 0.463
2022-01-02 16:22:37,617 [INFO] root - Epoch 8 - It. 1319: loss = 0.433
2022-01-02 16:23:31,631 [INFO] root - Epoch 8 - It. 1339: loss = 0.415
2022-01-02 16:24:25,538 [INFO] root - Epoch 8 - It. 1359: loss = 0.416
2022-01-02 16:25:19,381 [INFO] root - Epoch 8 - It. 1379: loss = 0.431
2022-01-02 16:26:13,399 [INFO] root - Epoch 8 - It. 1399: loss = 0.445
2022-01-02 16:26:47,686 [INFO] root - Starting the validation
2022-01-02 16:27:39,352 [INFO] root - VALIDATION -It. 1412: total loss: 0.443.
2022-01-02 16:27:39,353 [INFO] root - New best model (loss: 0.4435)
2022-01-02 16:27:39,354 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:27:39,828 [INFO] root - Training epoch: 9, LR: [0.0008337477621301496] 
2022-01-02 16:27:59,980 [INFO] root - Epoch 9 - It. 1419: loss = 0.442
2022-01-02 16:28:53,676 [INFO] root - Epoch 9 - It. 1439: loss = 0.431
2022-01-02 16:29:48,317 [INFO] root - Epoch 9 - It. 1459: loss = 0.449
2022-01-02 16:30:41,197 [INFO] root - Epoch 9 - It. 1479: loss = 0.416
2022-01-02 16:31:34,774 [INFO] root - Epoch 9 - It. 1499: loss = 0.415
2022-01-02 16:32:27,969 [INFO] root - Epoch 9 - It. 1519: loss = 0.421
2022-01-02 16:33:21,571 [INFO] root - Epoch 9 - It. 1539: loss = 0.428
2022-01-02 16:34:15,696 [INFO] root - Epoch 9 - It. 1559: loss = 0.440
2022-01-02 16:34:42,640 [INFO] root - Starting the validation
2022-01-02 16:35:34,083 [INFO] root - VALIDATION -It. 1569: total loss: 0.440.
2022-01-02 16:35:34,084 [INFO] root - New best model (loss: 0.4405)
2022-01-02 16:35:34,085 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:35:34,557 [INFO] root - Training epoch: 10, LR: [0.0008170728068875465] 
2022-01-02 16:36:02,513 [INFO] root - Epoch 10 - It. 1579: loss = 0.412
2022-01-02 16:36:56,706 [INFO] root - Epoch 10 - It. 1599: loss = 0.446
2022-01-02 16:37:50,524 [INFO] root - Epoch 10 - It. 1619: loss = 0.417
2022-01-02 16:38:43,892 [INFO] root - Epoch 10 - It. 1639: loss = 0.415
2022-01-02 16:39:37,726 [INFO] root - Epoch 10 - It. 1659: loss = 0.401
2022-01-02 16:40:31,697 [INFO] root - Epoch 10 - It. 1679: loss = 0.408
2022-01-02 16:41:25,493 [INFO] root - Epoch 10 - It. 1699: loss = 0.417
2022-01-02 16:42:19,506 [INFO] root - Epoch 10 - It. 1719: loss = 0.398
2022-01-02 16:42:38,560 [INFO] root - Starting the validation
2022-01-02 16:43:30,651 [INFO] root - VALIDATION -It. 1726: total loss: 0.424.
2022-01-02 16:43:30,652 [INFO] root - New best model (loss: 0.4244)
2022-01-02 16:43:30,653 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:43:31,118 [INFO] root - Training epoch: 11, LR: [0.0008007313507497956] 
2022-01-02 16:44:07,348 [INFO] root - Epoch 11 - It. 1739: loss = 0.418
2022-01-02 16:45:00,793 [INFO] root - Epoch 11 - It. 1759: loss = 0.372
2022-01-02 16:45:54,876 [INFO] root - Epoch 11 - It. 1779: loss = 0.427
2022-01-02 16:46:48,659 [INFO] root - Epoch 11 - It. 1799: loss = 0.365
2022-01-02 16:47:42,477 [INFO] root - Epoch 11 - It. 1819: loss = 0.426
2022-01-02 16:48:35,787 [INFO] root - Epoch 11 - It. 1839: loss = 0.376
2022-01-02 16:49:29,542 [INFO] root - Epoch 11 - It. 1859: loss = 0.381
2022-01-02 16:50:24,472 [INFO] root - Epoch 11 - It. 1879: loss = 0.413
2022-01-02 16:50:35,244 [INFO] root - Starting the validation
2022-01-02 16:51:26,731 [INFO] root - VALIDATION -It. 1883: total loss: 0.402.
2022-01-02 16:51:26,732 [INFO] root - New best model (loss: 0.4022)
2022-01-02 16:51:26,733 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:51:27,207 [INFO] root - Training epoch: 12, LR: [0.0007847167237347997] 
2022-01-02 16:52:11,317 [INFO] root - Epoch 12 - It. 1899: loss = 0.391
2022-01-02 16:53:05,458 [INFO] root - Epoch 12 - It. 1919: loss = 0.412
2022-01-02 16:54:00,171 [INFO] root - Epoch 12 - It. 1939: loss = 0.391
2022-01-02 16:54:53,316 [INFO] root - Epoch 12 - It. 1959: loss = 0.401
2022-01-02 16:55:47,504 [INFO] root - Epoch 12 - It. 1979: loss = 0.378
2022-01-02 16:56:41,295 [INFO] root - Epoch 12 - It. 1999: loss = 0.361
2022-01-02 16:57:34,337 [INFO] root - Epoch 12 - It. 2019: loss = 0.393
2022-01-02 16:58:28,618 [INFO] root - Epoch 12 - It. 2039: loss = 0.379
2022-01-02 16:58:31,140 [INFO] root - Starting the validation
2022-01-02 16:59:23,391 [INFO] root - VALIDATION -It. 2040: total loss: 0.398.
2022-01-02 16:59:23,392 [INFO] root - New best model (loss: 0.3983)
2022-01-02 16:59:23,393 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 16:59:23,865 [INFO] root - Training epoch: 13, LR: [0.0007690223892601037] 
2022-01-02 17:00:14,957 [INFO] root - Epoch 13 - It. 2059: loss = 0.362
2022-01-02 17:01:09,591 [INFO] root - Epoch 13 - It. 2079: loss = 0.378
2022-01-02 17:02:03,283 [INFO] root - Epoch 13 - It. 2099: loss = 0.365
2022-01-02 17:02:57,324 [INFO] root - Epoch 13 - It. 2119: loss = 0.372
2022-01-02 17:03:51,154 [INFO] root - Epoch 13 - It. 2139: loss = 0.366
2022-01-02 17:04:44,014 [INFO] root - Epoch 13 - It. 2159: loss = 0.385
2022-01-02 17:05:38,273 [INFO] root - Epoch 13 - It. 2179: loss = 0.342
2022-01-02 17:06:26,732 [INFO] root - Starting the validation
2022-01-02 17:07:18,400 [INFO] root - VALIDATION -It. 2197: total loss: 0.400.
2022-01-02 17:07:18,402 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2197.pt ...
2022-01-02 17:07:18,562 [INFO] root - Training epoch: 14, LR: [0.0007536419414749016] 
2022-01-02 17:07:24,719 [INFO] root - Epoch 14 - It. 2199: loss = 0.381
2022-01-02 17:08:19,356 [INFO] root - Epoch 14 - It. 2219: loss = 0.368
2022-01-02 17:09:13,196 [INFO] root - Epoch 14 - It. 2239: loss = 0.366
2022-01-02 17:10:07,531 [INFO] root - Epoch 14 - It. 2259: loss = 0.395
2022-01-02 17:11:01,439 [INFO] root - Epoch 14 - It. 2279: loss = 0.348
2022-01-02 17:11:55,260 [INFO] root - Epoch 14 - It. 2299: loss = 0.343
2022-01-02 17:12:48,640 [INFO] root - Epoch 14 - It. 2319: loss = 0.371
2022-01-02 17:13:42,255 [INFO] root - Epoch 14 - It. 2339: loss = 0.346
2022-01-02 17:14:23,272 [INFO] root - Starting the validation
2022-01-02 17:15:15,724 [INFO] root - VALIDATION -It. 2354: total loss: 0.382.
2022-01-02 17:15:15,726 [INFO] root - New best model (loss: 0.3817)
2022-01-02 17:15:15,727 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 17:15:16,209 [INFO] root - Training epoch: 15, LR: [0.0007385691026454036] 
2022-01-02 17:15:30,779 [INFO] root - Epoch 15 - It. 2359: loss = 0.363
2022-01-02 17:16:24,456 [INFO] root - Epoch 15 - It. 2379: loss = 0.355
2022-01-02 17:17:18,956 [INFO] root - Epoch 15 - It. 2399: loss = 0.339
2022-01-02 17:18:13,342 [INFO] root - Epoch 15 - It. 2419: loss = 0.347
2022-01-02 17:19:07,018 [INFO] root - Epoch 15 - It. 2439: loss = 0.340
2022-01-02 17:20:00,324 [INFO] root - Epoch 15 - It. 2459: loss = 0.330
2022-01-02 17:20:54,223 [INFO] root - Epoch 15 - It. 2479: loss = 0.337
2022-01-02 17:21:47,507 [INFO] root - Epoch 15 - It. 2499: loss = 0.333
2022-01-02 17:22:20,152 [INFO] root - Starting the validation
2022-01-02 17:23:11,966 [INFO] root - VALIDATION -It. 2511: total loss: 0.376.
2022-01-02 17:23:11,967 [INFO] root - New best model (loss: 0.3764)
2022-01-02 17:23:11,968 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 17:23:12,437 [INFO] root - Training epoch: 16, LR: [0.0007237977205924955] 
2022-01-02 17:23:35,065 [INFO] root - Epoch 16 - It. 2519: loss = 0.370
2022-01-02 17:24:28,094 [INFO] root - Epoch 16 - It. 2539: loss = 0.339
2022-01-02 17:25:21,488 [INFO] root - Epoch 16 - It. 2559: loss = 0.348
2022-01-02 17:26:16,299 [INFO] root - Epoch 16 - It. 2579: loss = 0.355
2022-01-02 17:27:10,887 [INFO] root - Epoch 16 - It. 2599: loss = 0.375
2022-01-02 17:28:04,354 [INFO] root - Epoch 16 - It. 2619: loss = 0.334
2022-01-02 17:28:57,613 [INFO] root - Epoch 16 - It. 2639: loss = 0.317
2022-01-02 17:29:51,279 [INFO] root - Epoch 16 - It. 2659: loss = 0.330
2022-01-02 17:30:15,508 [INFO] root - Starting the validation
2022-01-02 17:31:07,468 [INFO] root - VALIDATION -It. 2668: total loss: 0.365.
2022-01-02 17:31:07,469 [INFO] root - New best model (loss: 0.3651)
2022-01-02 17:31:07,470 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 17:31:07,941 [INFO] root - Training epoch: 17, LR: [0.0007093217661806456] 
2022-01-02 17:31:39,104 [INFO] root - Epoch 17 - It. 2679: loss = 0.326
2022-01-02 17:32:32,650 [INFO] root - Epoch 17 - It. 2699: loss = 0.309
2022-01-02 17:33:26,468 [INFO] root - Epoch 17 - It. 2719: loss = 0.324
2022-01-02 17:34:21,069 [INFO] root - Epoch 17 - It. 2739: loss = 0.331
2022-01-02 17:35:14,225 [INFO] root - Epoch 17 - It. 2759: loss = 0.329
2022-01-02 17:36:06,847 [INFO] root - Epoch 17 - It. 2779: loss = 0.337
2022-01-02 17:37:00,999 [INFO] root - Epoch 17 - It. 2799: loss = 0.328
2022-01-02 17:37:54,574 [INFO] root - Epoch 17 - It. 2819: loss = 0.343
2022-01-02 17:38:10,755 [INFO] root - Starting the validation
2022-01-02 17:39:02,715 [INFO] root - VALIDATION -It. 2825: total loss: 0.348.
2022-01-02 17:39:02,716 [INFO] root - New best model (loss: 0.3481)
2022-01-02 17:39:02,717 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 17:39:03,188 [INFO] root - Training epoch: 18, LR: [0.0006951353308570327] 
2022-01-02 17:39:41,838 [INFO] root - Epoch 18 - It. 2839: loss = 0.332
2022-01-02 17:40:35,668 [INFO] root - Epoch 18 - It. 2859: loss = 0.341
2022-01-02 17:41:29,960 [INFO] root - Epoch 18 - It. 2879: loss = 0.325
2022-01-02 17:42:23,231 [INFO] root - Epoch 18 - It. 2899: loss = 0.336
2022-01-02 17:43:17,236 [INFO] root - Epoch 18 - It. 2919: loss = 0.301
2022-01-02 17:44:10,902 [INFO] root - Epoch 18 - It. 2939: loss = 0.325
2022-01-02 17:45:04,166 [INFO] root - Epoch 18 - It. 2959: loss = 0.309
2022-01-02 17:45:58,045 [INFO] root - Epoch 18 - It. 2979: loss = 0.303
2022-01-02 17:46:06,430 [INFO] root - Starting the validation
2022-01-02 17:46:58,759 [INFO] root - VALIDATION -It. 2982: total loss: 0.353.
2022-01-02 17:46:58,760 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2982.pt ...
2022-01-02 17:46:58,921 [INFO] root - Training epoch: 19, LR: [0.000681232624239892] 
2022-01-02 17:47:46,689 [INFO] root - Epoch 19 - It. 2999: loss = 0.320
2022-01-02 17:48:40,576 [INFO] root - Epoch 19 - It. 3019: loss = 0.302
2022-01-02 17:49:34,389 [INFO] root - Epoch 19 - It. 3039: loss = 0.323
2022-01-02 17:50:27,816 [INFO] root - Epoch 19 - It. 3059: loss = 0.308
2022-01-02 17:51:21,583 [INFO] root - Epoch 19 - It. 3079: loss = 0.287
2022-01-02 17:52:14,158 [INFO] root - Epoch 19 - It. 3099: loss = 0.329
2022-01-02 17:53:08,408 [INFO] root - Epoch 19 - It. 3119: loss = 0.325
2022-01-02 17:54:02,961 [INFO] root - Epoch 19 - It. 3139: loss = 0.294
2022-01-02 17:54:02,965 [INFO] root - Starting the validation
2022-01-02 17:54:55,316 [INFO] root - VALIDATION -It. 3139: total loss: 0.367.
2022-01-02 17:54:55,318 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3139.pt ...
2022-01-02 17:54:55,479 [INFO] root - Training epoch: 20, LR: [0.0006676079717550942] 
2022-01-02 17:55:50,794 [INFO] root - Epoch 20 - It. 3159: loss = 0.299
2022-01-02 17:56:43,929 [INFO] root - Epoch 20 - It. 3179: loss = 0.315
2022-01-02 17:57:37,135 [INFO] root - Epoch 20 - It. 3199: loss = 0.303
2022-01-02 17:58:31,061 [INFO] root - Epoch 20 - It. 3219: loss = 0.308
2022-01-02 17:59:25,177 [INFO] root - Epoch 20 - It. 3239: loss = 0.297
2022-01-02 18:00:19,372 [INFO] root - Epoch 20 - It. 3259: loss = 0.305
2022-01-02 18:01:12,441 [INFO] root - Epoch 20 - It. 3279: loss = 0.316
2022-01-02 18:01:58,278 [INFO] root - Starting the validation
2022-01-02 18:02:50,343 [INFO] root - VALIDATION -It. 3296: total loss: 0.330.
2022-01-02 18:02:50,345 [INFO] root - New best model (loss: 0.3296)
2022-01-02 18:02:50,345 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 18:02:50,814 [INFO] root - Training epoch: 21, LR: [0.0006542558123199924] 
2022-01-02 18:03:00,242 [INFO] root - Epoch 21 - It. 3299: loss = 0.330
2022-01-02 18:03:54,218 [INFO] root - Epoch 21 - It. 3319: loss = 0.307
2022-01-02 18:04:47,815 [INFO] root - Epoch 21 - It. 3339: loss = 0.303
2022-01-02 18:05:42,633 [INFO] root - Epoch 21 - It. 3359: loss = 0.289
2022-01-02 18:06:37,228 [INFO] root - Epoch 21 - It. 3379: loss = 0.299
2022-01-02 18:07:30,357 [INFO] root - Epoch 21 - It. 3399: loss = 0.310
2022-01-02 18:08:24,142 [INFO] root - Epoch 21 - It. 3419: loss = 0.280
2022-01-02 18:09:17,851 [INFO] root - Epoch 21 - It. 3439: loss = 0.275
2022-01-02 18:09:55,650 [INFO] root - Starting the validation
2022-01-02 18:10:47,274 [INFO] root - VALIDATION -It. 3453: total loss: 0.335.
2022-01-02 18:10:47,275 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3453.pt ...
2022-01-02 18:10:47,439 [INFO] root - Training epoch: 22, LR: [0.0006411706960735925] 
2022-01-02 18:11:04,438 [INFO] root - Epoch 22 - It. 3459: loss = 0.276
2022-01-02 18:11:58,107 [INFO] root - Epoch 22 - It. 3479: loss = 0.281
2022-01-02 18:12:51,410 [INFO] root - Epoch 22 - It. 3499: loss = 0.279
2022-01-02 18:13:45,579 [INFO] root - Epoch 22 - It. 3519: loss = 0.271
2022-01-02 18:14:39,949 [INFO] root - Epoch 22 - It. 3539: loss = 0.287
2022-01-02 18:15:33,454 [INFO] root - Epoch 22 - It. 3559: loss = 0.304
2022-01-02 18:16:28,128 [INFO] root - Epoch 22 - It. 3579: loss = 0.288
2022-01-02 18:17:21,495 [INFO] root - Epoch 22 - It. 3599: loss = 0.265
2022-01-02 18:17:50,581 [INFO] root - Starting the validation
2022-01-02 18:18:42,638 [INFO] root - VALIDATION -It. 3610: total loss: 0.349.
2022-01-02 18:18:42,640 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3610.pt ...
2022-01-02 18:18:42,802 [INFO] root - Training epoch: 23, LR: [0.0006283472821521206] 
2022-01-02 18:19:08,670 [INFO] root - Epoch 23 - It. 3619: loss = 0.276
2022-01-02 18:20:02,281 [INFO] root - Epoch 23 - It. 3639: loss = 0.271
2022-01-02 18:20:56,025 [INFO] root - Epoch 23 - It. 3659: loss = 0.280
2022-01-02 18:21:49,805 [INFO] root - Epoch 23 - It. 3679: loss = 0.298
2022-01-02 18:22:44,275 [INFO] root - Epoch 23 - It. 3699: loss = 0.298
2022-01-02 18:23:38,535 [INFO] root - Epoch 23 - It. 3719: loss = 0.287
2022-01-02 18:24:31,987 [INFO] root - Epoch 23 - It. 3739: loss = 0.272
2022-01-02 18:25:25,423 [INFO] root - Epoch 23 - It. 3759: loss = 0.274
2022-01-02 18:25:46,478 [INFO] root - Starting the validation
2022-01-02 18:26:38,510 [INFO] root - VALIDATION -It. 3767: total loss: 0.334.
2022-01-02 18:26:38,512 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3767.pt ...
2022-01-02 18:26:38,671 [INFO] root - Training epoch: 24, LR: [0.0006157803365090782] 
2022-01-02 18:27:11,923 [INFO] root - Epoch 24 - It. 3779: loss = 0.286
2022-01-02 18:28:06,069 [INFO] root - Epoch 24 - It. 3799: loss = 0.267
2022-01-02 18:28:59,645 [INFO] root - Epoch 24 - It. 3819: loss = 0.264
2022-01-02 18:29:54,176 [INFO] root - Epoch 24 - It. 3839: loss = 0.270
2022-01-02 18:30:48,047 [INFO] root - Epoch 24 - It. 3859: loss = 0.268
2022-01-02 18:31:41,899 [INFO] root - Epoch 24 - It. 3879: loss = 0.283
2022-01-02 18:32:36,641 [INFO] root - Epoch 24 - It. 3899: loss = 0.282
2022-01-02 18:33:30,057 [INFO] root - Epoch 24 - It. 3919: loss = 0.298
2022-01-02 18:33:43,722 [INFO] root - Starting the validation
2022-01-02 18:34:36,170 [INFO] root - VALIDATION -It. 3924: total loss: 0.332.
2022-01-02 18:34:36,172 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3924.pt ...
2022-01-02 18:34:36,332 [INFO] root - Training epoch: 25, LR: [0.0006034647297788967] 
2022-01-02 18:35:17,729 [INFO] root - Epoch 25 - It. 3939: loss = 0.269
2022-01-02 18:36:11,601 [INFO] root - Epoch 25 - It. 3959: loss = 0.254
2022-01-02 18:37:05,722 [INFO] root - Epoch 25 - It. 3979: loss = 0.279
2022-01-02 18:37:59,882 [INFO] root - Epoch 25 - It. 3999: loss = 0.268
2022-01-02 18:38:53,778 [INFO] root - Epoch 25 - It. 4019: loss = 0.269
2022-01-02 18:39:47,746 [INFO] root - Epoch 25 - It. 4039: loss = 0.277
2022-01-02 18:40:41,486 [INFO] root - Epoch 25 - It. 4059: loss = 0.293
2022-01-02 18:41:34,731 [INFO] root - Epoch 25 - It. 4079: loss = 0.269
2022-01-02 18:41:40,220 [INFO] root - Starting the validation
2022-01-02 18:42:32,508 [INFO] root - VALIDATION -It. 4081: total loss: 0.338.
2022-01-02 18:42:32,510 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4081.pt ...
2022-01-02 18:42:32,671 [INFO] root - Training epoch: 26, LR: [0.0005913954351833187] 
2022-01-02 18:43:22,819 [INFO] root - Epoch 26 - It. 4099: loss = 0.260
2022-01-02 18:44:16,639 [INFO] root - Epoch 26 - It. 4119: loss = 0.271
2022-01-02 18:45:09,964 [INFO] root - Epoch 26 - It. 4139: loss = 0.285
2022-01-02 18:46:02,870 [INFO] root - Epoch 26 - It. 4159: loss = 0.252
2022-01-02 18:46:57,619 [INFO] root - Epoch 26 - It. 4179: loss = 0.260
2022-01-02 18:47:51,286 [INFO] root - Epoch 26 - It. 4199: loss = 0.257
2022-01-02 18:48:45,771 [INFO] root - Epoch 26 - It. 4219: loss = 0.263
2022-01-02 18:49:37,390 [INFO] root - Starting the validation
2022-01-02 18:50:29,867 [INFO] root - VALIDATION -It. 4238: total loss: 0.300.
2022-01-02 18:50:29,868 [INFO] root - New best model (loss: 0.2997)
2022-01-02 18:50:29,869 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 18:50:30,349 [INFO] root - Training epoch: 27, LR: [0.0005795675264796523] 
2022-01-02 18:50:34,312 [INFO] root - Epoch 27 - It. 4239: loss = 0.254
2022-01-02 18:51:27,914 [INFO] root - Epoch 27 - It. 4259: loss = 0.243
2022-01-02 18:52:22,037 [INFO] root - Epoch 27 - It. 4279: loss = 0.241
2022-01-02 18:53:15,895 [INFO] root - Epoch 27 - It. 4299: loss = 0.258
2022-01-02 18:54:09,736 [INFO] root - Epoch 27 - It. 4319: loss = 0.264
2022-01-02 18:55:03,307 [INFO] root - Epoch 27 - It. 4339: loss = 0.251
2022-01-02 18:55:57,286 [INFO] root - Epoch 27 - It. 4359: loss = 0.243
2022-01-02 18:56:51,689 [INFO] root - Epoch 27 - It. 4379: loss = 0.248
2022-01-02 18:57:34,009 [INFO] root - Starting the validation
2022-01-02 18:58:26,684 [INFO] root - VALIDATION -It. 4395: total loss: 0.308.
2022-01-02 18:58:26,686 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4395.pt ...
2022-01-02 18:58:26,849 [INFO] root - Training epoch: 28, LR: [0.0005679761759500593] 
2022-01-02 18:58:39,054 [INFO] root - Epoch 28 - It. 4399: loss = 0.264
2022-01-02 18:59:33,176 [INFO] root - Epoch 28 - It. 4419: loss = 0.233
2022-01-02 19:00:27,408 [INFO] root - Epoch 28 - It. 4439: loss = 0.249
2022-01-02 19:01:21,576 [INFO] root - Epoch 28 - It. 4459: loss = 0.256
2022-01-02 19:02:14,074 [INFO] root - Epoch 28 - It. 4479: loss = 0.272
2022-01-02 19:03:07,973 [INFO] root - Epoch 28 - It. 4499: loss = 0.237
2022-01-02 19:04:01,447 [INFO] root - Epoch 28 - It. 4519: loss = 0.275
2022-01-02 19:04:55,967 [INFO] root - Epoch 28 - It. 4539: loss = 0.261
2022-01-02 19:05:31,061 [INFO] root - Starting the validation
2022-01-02 19:06:23,740 [INFO] root - VALIDATION -It. 4552: total loss: 0.315.
2022-01-02 19:06:23,742 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4552.pt ...
2022-01-02 19:06:23,912 [INFO] root - Training epoch: 29, LR: [0.0005566166524310581] 
2022-01-02 19:06:44,230 [INFO] root - Epoch 29 - It. 4559: loss = 0.250
2022-01-02 19:07:38,700 [INFO] root - Epoch 29 - It. 4579: loss = 0.266
2022-01-02 19:08:32,786 [INFO] root - Epoch 29 - It. 4599: loss = 0.256
2022-01-02 19:09:26,895 [INFO] root - Epoch 29 - It. 4619: loss = 0.244
2022-01-02 19:10:20,364 [INFO] root - Epoch 29 - It. 4639: loss = 0.265
2022-01-02 19:11:14,284 [INFO] root - Epoch 29 - It. 4659: loss = 0.252
2022-01-02 19:12:08,389 [INFO] root - Epoch 29 - It. 4679: loss = 0.241
2022-01-02 19:13:02,151 [INFO] root - Epoch 29 - It. 4699: loss = 0.244
2022-01-02 19:13:29,725 [INFO] root - Starting the validation
2022-01-02 19:14:21,604 [INFO] root - VALIDATION -It. 4709: total loss: 0.304.
2022-01-02 19:14:21,606 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4709.pt ...
2022-01-02 19:14:21,770 [INFO] root - Training epoch: 30, LR: [0.0005454843193824369] 
2022-01-02 19:14:50,184 [INFO] root - Epoch 30 - It. 4719: loss = 0.236
2022-01-02 19:15:45,245 [INFO] root - Epoch 30 - It. 4739: loss = 0.255
2022-01-02 19:16:37,860 [INFO] root - Epoch 30 - It. 4759: loss = 0.227
2022-01-02 19:17:31,640 [INFO] root - Epoch 30 - It. 4779: loss = 0.248
2022-01-02 19:18:25,678 [INFO] root - Epoch 30 - It. 4799: loss = 0.263
2022-01-02 19:19:19,437 [INFO] root - Epoch 30 - It. 4819: loss = 0.236
2022-01-02 19:20:14,379 [INFO] root - Epoch 30 - It. 4839: loss = 0.245
2022-01-02 19:21:07,601 [INFO] root - Epoch 30 - It. 4859: loss = 0.256
2022-01-02 19:21:26,504 [INFO] root - Starting the validation
2022-01-02 19:22:19,067 [INFO] root - VALIDATION -It. 4866: total loss: 0.292.
2022-01-02 19:22:19,068 [INFO] root - New best model (loss: 0.2915)
2022-01-02 19:22:19,069 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 19:22:19,540 [INFO] root - Training epoch: 31, LR: [0.0005345746329947881] 
2022-01-02 19:22:55,025 [INFO] root - Epoch 31 - It. 4879: loss = 0.237
2022-01-02 19:23:48,686 [INFO] root - Epoch 31 - It. 4899: loss = 0.255
2022-01-02 19:24:42,456 [INFO] root - Epoch 31 - It. 4919: loss = 0.255
2022-01-02 19:25:37,089 [INFO] root - Epoch 31 - It. 4939: loss = 0.250
2022-01-02 19:26:30,839 [INFO] root - Epoch 31 - It. 4959: loss = 0.252
2022-01-02 19:27:25,255 [INFO] root - Epoch 31 - It. 4979: loss = 0.251
2022-01-02 19:28:19,840 [INFO] root - Epoch 31 - It. 4999: loss = 0.250
2022-01-02 19:29:13,642 [INFO] root - Epoch 31 - It. 5019: loss = 0.227
2022-01-02 19:29:24,815 [INFO] root - Starting the validation
2022-01-02 19:30:16,914 [INFO] root - VALIDATION -It. 5023: total loss: 0.306.
2022-01-02 19:30:16,916 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5023.pt ...
2022-01-02 19:30:17,078 [INFO] root - Training epoch: 32, LR: [0.0005238831403348923] 
2022-01-02 19:31:00,857 [INFO] root - Epoch 32 - It. 5039: loss = 0.259
2022-01-02 19:31:54,582 [INFO] root - Epoch 32 - It. 5059: loss = 0.244
2022-01-02 19:32:48,443 [INFO] root - Epoch 32 - It. 5079: loss = 0.238
2022-01-02 19:33:42,292 [INFO] root - Epoch 32 - It. 5099: loss = 0.245
2022-01-02 19:34:36,750 [INFO] root - Epoch 32 - It. 5119: loss = 0.237
2022-01-02 19:35:30,877 [INFO] root - Epoch 32 - It. 5139: loss = 0.261
2022-01-02 19:36:24,883 [INFO] root - Epoch 32 - It. 5159: loss = 0.255
2022-01-02 19:37:19,143 [INFO] root - Epoch 32 - It. 5179: loss = 0.224
2022-01-02 19:37:21,880 [INFO] root - Starting the validation
2022-01-02 19:38:14,413 [INFO] root - VALIDATION -It. 5180: total loss: 0.300.
2022-01-02 19:38:14,415 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5180.pt ...
2022-01-02 19:38:14,578 [INFO] root - Training epoch: 33, LR: [0.0005134054775281945] 
2022-01-02 19:39:07,328 [INFO] root - Epoch 33 - It. 5199: loss = 0.213
2022-01-02 19:40:00,437 [INFO] root - Epoch 33 - It. 5219: loss = 0.257
2022-01-02 19:40:54,654 [INFO] root - Epoch 33 - It. 5239: loss = 0.244
2022-01-02 19:41:48,610 [INFO] root - Epoch 33 - It. 5259: loss = 0.237
2022-01-02 19:42:42,412 [INFO] root - Epoch 33 - It. 5279: loss = 0.230
2022-01-02 19:43:36,863 [INFO] root - Epoch 33 - It. 5299: loss = 0.261
2022-01-02 19:44:31,124 [INFO] root - Epoch 33 - It. 5319: loss = 0.232
2022-01-02 19:45:20,120 [INFO] root - Starting the validation
2022-01-02 19:46:12,697 [INFO] root - VALIDATION -It. 5337: total loss: 0.296.
2022-01-02 19:46:12,698 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5337.pt ...
2022-01-02 19:46:12,861 [INFO] root - Training epoch: 34, LR: [0.0005031373679776305] 
2022-01-02 19:46:19,347 [INFO] root - Epoch 34 - It. 5339: loss = 0.216
2022-01-02 19:47:13,700 [INFO] root - Epoch 34 - It. 5359: loss = 0.253
2022-01-02 19:48:08,180 [INFO] root - Epoch 34 - It. 5379: loss = 0.229
2022-01-02 19:49:02,108 [INFO] root - Epoch 34 - It. 5399: loss = 0.233
2022-01-02 19:49:56,224 [INFO] root - Epoch 34 - It. 5419: loss = 0.237
2022-01-02 19:50:49,975 [INFO] root - Epoch 34 - It. 5439: loss = 0.229
2022-01-02 19:51:43,445 [INFO] root - Epoch 34 - It. 5459: loss = 0.242
2022-01-02 19:52:37,335 [INFO] root - Epoch 34 - It. 5479: loss = 0.240
2022-01-02 19:53:18,458 [INFO] root - Starting the validation
2022-01-02 19:54:11,142 [INFO] root - VALIDATION -It. 5494: total loss: 0.281.
2022-01-02 19:54:11,143 [INFO] root - New best model (loss: 0.2810)
2022-01-02 19:54:11,144 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-02 19:54:11,617 [INFO] root - Training epoch: 35, LR: [0.0004930746206180779] 
2022-01-02 19:54:26,478 [INFO] root - Epoch 35 - It. 5499: loss = 0.221
2022-01-02 19:55:18,886 [INFO] root - Epoch 35 - It. 5519: loss = 0.248
2022-01-02 19:56:12,800 [INFO] root - Epoch 35 - It. 5539: loss = 0.230
2022-01-02 19:57:07,373 [INFO] root - Epoch 35 - It. 5559: loss = 0.231
2022-01-02 19:58:01,162 [INFO] root - Epoch 35 - It. 5579: loss = 0.223
2022-01-02 19:58:55,148 [INFO] root - Epoch 35 - It. 5599: loss = 0.225
2022-01-02 19:59:49,463 [INFO] root - Epoch 35 - It. 5619: loss = 0.227
2022-01-02 20:00:44,356 [INFO] root - Epoch 35 - It. 5639: loss = 0.227
2022-01-02 20:01:16,266 [INFO] root - Starting the validation
2022-01-02 20:02:08,566 [INFO] root - VALIDATION -It. 5651: total loss: 0.283.
2022-01-02 20:02:08,567 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5651.pt ...
2022-01-02 20:02:08,731 [INFO] root - Training epoch: 36, LR: [0.00048321312820571636] 
2022-01-02 20:02:32,432 [INFO] root - Epoch 36 - It. 5659: loss = 0.232
2022-01-02 20:03:25,638 [INFO] root - Epoch 36 - It. 5679: loss = 0.234
2022-01-02 20:04:19,935 [INFO] root - Epoch 36 - It. 5699: loss = 0.233
2022-01-02 20:05:15,435 [INFO] root - Epoch 36 - It. 5719: loss = 0.218
2022-01-02 20:06:09,190 [INFO] root - Epoch 36 - It. 5739: loss = 0.231
2022-01-02 20:07:02,958 [INFO] root - Epoch 36 - It. 5759: loss = 0.220
2022-01-02 20:07:56,445 [INFO] root - Epoch 36 - It. 5779: loss = 0.230
2022-01-02 20:08:51,409 [INFO] root - Epoch 36 - It. 5799: loss = 0.212
2022-01-02 20:09:14,788 [INFO] root - Starting the validation
2022-01-02 20:10:07,561 [INFO] root - VALIDATION -It. 5808: total loss: 0.285.
2022-01-02 20:10:07,563 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5808.pt ...
2022-01-02 20:10:07,723 [INFO] root - Training epoch: 37, LR: [0.00047354886564160203] 
2022-01-02 20:10:38,749 [INFO] root - Epoch 37 - It. 5819: loss = 0.223
2022-01-02 20:11:32,503 [INFO] root - Epoch 37 - It. 5839: loss = 0.241
2022-01-02 20:12:25,862 [INFO] root - Epoch 37 - It. 5859: loss = 0.218
2022-01-02 20:13:19,528 [INFO] root - Epoch 37 - It. 5879: loss = 0.231
2022-01-02 20:14:12,573 [INFO] root - Epoch 37 - It. 5899: loss = 0.209
2022-01-02 20:15:06,371 [INFO] root - Epoch 37 - It. 5919: loss = 0.219
2022-01-02 20:16:00,751 [INFO] root - Epoch 37 - It. 5939: loss = 0.232
2022-01-02 20:16:54,672 [INFO] root - Epoch 37 - It. 5959: loss = 0.233
2022-01-02 20:17:11,862 [INFO] root - Starting the validation
2022-01-02 20:18:04,584 [INFO] root - VALIDATION -It. 5965: total loss: 0.283.
2022-01-02 20:18:04,585 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5965.pt ...
2022-01-02 20:18:04,751 [INFO] root - Training epoch: 38, LR: [0.00046407788832877] 
2022-01-02 20:18:44,422 [INFO] root - Epoch 38 - It. 5979: loss = 0.221
2022-01-02 20:19:39,169 [INFO] root - Epoch 38 - It. 5999: loss = 0.217
2022-01-02 20:20:32,392 [INFO] root - Epoch 38 - It. 6019: loss = 0.216
2022-01-02 20:21:26,385 [INFO] root - Epoch 38 - It. 6039: loss = 0.223
2022-01-02 20:22:20,213 [INFO] root - Epoch 38 - It. 6059: loss = 0.234
2022-01-02 20:23:14,384 [INFO] root - Epoch 38 - It. 6079: loss = 0.220
2022-01-02 20:24:08,658 [INFO] root - Epoch 38 - It. 6099: loss = 0.226
2022-01-02 20:25:02,437 [INFO] root - Epoch 38 - It. 6119: loss = 0.236
2022-01-02 20:25:10,669 [INFO] root - Starting the validation
2022-01-02 20:26:03,320 [INFO] root - VALIDATION -It. 6122: total loss: 0.305.
2022-01-02 20:26:03,321 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_6122.pt ...
2022-01-02 20:26:03,484 [INFO] root - Training epoch: 39, LR: [0.0004547963305621946] 
2022-01-02 20:26:50,391 [INFO] root - Epoch 39 - It. 6139: loss = 0.234
2022-01-02 20:27:45,033 [INFO] root - Epoch 39 - It. 6159: loss = 0.217
2022-01-02 20:28:40,387 [INFO] root - Epoch 39 - It. 6179: loss = 0.217
2022-01-02 20:29:33,075 [INFO] root - Epoch 39 - It. 6199: loss = 0.217
2022-01-02 20:30:27,419 [INFO] root - Epoch 39 - It. 6219: loss = 0.221
2022-01-02 20:31:21,330 [INFO] root - Epoch 39 - It. 6239: loss = 0.215
2022-01-02 20:32:15,304 [INFO] root - Epoch 39 - It. 6259: loss = 0.226
2022-01-02 20:33:08,943 [INFO] root - Epoch 39 - It. 6279: loss = 0.217
2022-01-02 20:33:08,947 [INFO] root - Starting the validation
2022-01-02 20:34:01,330 [INFO] root - VALIDATION -It. 6279: total loss: 0.287.
2022-01-02 20:34:01,331 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_02-15_16_27_741413__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_6279.pt ...
2022-01-02 20:34:01,501 [INFO] root - Training completed after 39 Epochs (156 it) with best val metric (total_loss)=0.2809838354587555
