2022-01-05 12:27:39,745 [INFO] root - Command: train.py ./configs/train/train_weakly_supervised.yaml
2022-01-05 12:27:39,746 [INFO] root - Arguments: method_backbone: ME, method_flow: True, method_ego_motion: True, method_semantic: True, method_clustering: True, method_loop_ego: False, method_loop_flow: False, method_umeyama: False, method_background_flow: True, misc_voxel_size: 0.1, misc_num_points: 8192, misc_trainer: FlowTrainer, misc_use_gpu: True, misc_log_dir: ./logs/, misc_run_mode: train, data_input_features: absolute_coords, data_only_near_points: True, data_dataset: SemanticKITTI_ME, data_root: ./data/semantic_kitti/, data_n_classes: 2, data_remove_ground: True, data_augment_data: True, train_batch_size: 6, train_acc_iter_size: 1, train_num_workers: 6, train_max_epoch: 39, train_stat_interval: 20, train_chkpt_interval: -1, train_val_interval: -1, train_weighted_seg_loss: True, val_batch_size: 6, val_num_workers: 6, test_results_dir: ./eval/, test_batch_size: 1, test_num_workers: 1, loss_bg_loss_w: 1.0, loss_fg_loss_w: 1.0, loss_flow_loss_w: 1.0, loss_ego_loss_w: 1.0, loss_inlier_loss_w: 0.005, loss_cd_loss_w: 0.5, loss_rigid_loss_w: 1.0, loss_background_loss: True, loss_flow_loss: False, loss_ego_loss: True, loss_foreground_loss: True, optimizer_alg: Adam, optimizer_learning_rate: 0.001, optimizer_weight_decay: 0.0, optimizer_momentum: 0.8, optimizer_scheduler: ExponentialLR, optimizer_exp_gamma: 0.98, network_normalize_features: True, network_norm_type: IN, network_in_kernel_size: 7, network_feature_dim: 64, network_ego_motion_points: 1024, network_add_slack: True, network_sinkhorn_iter: 3, network_use_pretrained: True, network_cluster_metric: euclidean, network_min_p_cluster: 30, network_min_samples_dbscan: 5, network_eps_dbscan: 0.75, network_pretrained_path: , metrics_flow: False, metrics_ego_motion: True, metrics_semantic: True
2022-01-05 12:27:39,746 [INFO] root - Output and logs will be saved to ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192
2022-01-05 12:27:39,748 [INFO] root - Parameter Count: 8078149
2022-01-05 12:27:39,748 [INFO] root - Torch version: 1.7.1+cu110
2022-01-05 12:27:39,748 [INFO] root - CUDA version: 11.0
2022-01-05 12:27:39,756 [INFO] root - Training epoch: 0, LR: [0.001] 
2022-01-05 12:28:24,448 [INFO] root - Epoch 0 - It. 19: loss = 1.891
2022-01-05 12:29:08,244 [INFO] root - Epoch 0 - It. 39: loss = 1.489
2022-01-05 12:29:50,998 [INFO] root - Epoch 0 - It. 59: loss = 1.307
2022-01-05 12:30:34,330 [INFO] root - Epoch 0 - It. 79: loss = 1.165
2022-01-05 12:31:17,324 [INFO] root - Epoch 0 - It. 99: loss = 1.024
2022-01-05 12:31:59,668 [INFO] root - Epoch 0 - It. 119: loss = 0.910
2022-01-05 12:32:41,921 [INFO] root - Epoch 0 - It. 139: loss = 0.808
2022-01-05 12:33:18,510 [INFO] root - Starting the validation
2022-01-05 12:33:59,761 [INFO] root - VALIDATION -It. 156: total loss: 0.708.
2022-01-05 12:33:59,762 [INFO] root - New best model (loss: 0.7078)
2022-01-05 12:33:59,763 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 12:33:59,922 [INFO] root - Training epoch: 1, LR: [0.00098] 
2022-01-05 12:34:07,228 [INFO] root - Epoch 1 - It. 159: loss = 0.798
2022-01-05 12:34:50,189 [INFO] root - Epoch 1 - It. 179: loss = 0.753
2022-01-05 12:35:32,797 [INFO] root - Epoch 1 - It. 199: loss = 0.722
2022-01-05 12:36:15,322 [INFO] root - Epoch 1 - It. 219: loss = 0.737
2022-01-05 12:36:58,274 [INFO] root - Epoch 1 - It. 239: loss = 0.700
2022-01-05 12:37:41,822 [INFO] root - Epoch 1 - It. 259: loss = 0.694
2022-01-05 12:38:24,766 [INFO] root - Epoch 1 - It. 279: loss = 0.671
2022-01-05 12:39:07,251 [INFO] root - Epoch 1 - It. 299: loss = 0.631
2022-01-05 12:39:37,267 [INFO] root - Starting the validation
2022-01-05 12:40:18,230 [INFO] root - VALIDATION -It. 313: total loss: 0.606.
2022-01-05 12:40:18,231 [INFO] root - New best model (loss: 0.6057)
2022-01-05 12:40:18,231 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 12:40:18,707 [INFO] root - Training epoch: 2, LR: [0.0009603999999999999] 
2022-01-05 12:40:32,484 [INFO] root - Epoch 2 - It. 319: loss = 0.642
2022-01-05 12:41:16,137 [INFO] root - Epoch 2 - It. 339: loss = 0.619
2022-01-05 12:41:58,896 [INFO] root - Epoch 2 - It. 359: loss = 0.622
2022-01-05 12:42:41,683 [INFO] root - Epoch 2 - It. 379: loss = 0.608
2022-01-05 12:43:24,316 [INFO] root - Epoch 2 - It. 399: loss = 0.594
2022-01-05 12:44:07,287 [INFO] root - Epoch 2 - It. 419: loss = 0.586
2022-01-05 12:44:49,647 [INFO] root - Epoch 2 - It. 439: loss = 0.555
2022-01-05 12:45:32,524 [INFO] root - Epoch 2 - It. 459: loss = 0.532
2022-01-05 12:45:56,129 [INFO] root - Starting the validation
2022-01-05 12:46:37,049 [INFO] root - VALIDATION -It. 470: total loss: 0.518.
2022-01-05 12:46:37,050 [INFO] root - New best model (loss: 0.5176)
2022-01-05 12:46:37,051 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 12:46:37,523 [INFO] root - Training epoch: 3, LR: [0.0009411919999999999] 
2022-01-05 12:46:57,699 [INFO] root - Epoch 3 - It. 479: loss = 0.522
2022-01-05 12:47:40,337 [INFO] root - Epoch 3 - It. 499: loss = 0.504
2022-01-05 12:48:23,212 [INFO] root - Epoch 3 - It. 519: loss = 0.503
2022-01-05 12:49:05,998 [INFO] root - Epoch 3 - It. 539: loss = 0.561
2022-01-05 12:49:48,129 [INFO] root - Epoch 3 - It. 559: loss = 0.543
2022-01-05 12:50:30,850 [INFO] root - Epoch 3 - It. 579: loss = 0.508
2022-01-05 12:51:14,134 [INFO] root - Epoch 3 - It. 599: loss = 0.522
2022-01-05 12:51:57,052 [INFO] root - Epoch 3 - It. 619: loss = 0.490
2022-01-05 12:52:14,356 [INFO] root - Starting the validation
2022-01-05 12:52:55,589 [INFO] root - VALIDATION -It. 627: total loss: 0.495.
2022-01-05 12:52:55,589 [INFO] root - New best model (loss: 0.4946)
2022-01-05 12:52:55,591 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 12:52:56,060 [INFO] root - Training epoch: 4, LR: [0.0009223681599999998] 
2022-01-05 12:53:22,589 [INFO] root - Epoch 4 - It. 639: loss = 0.501
2022-01-05 12:54:05,382 [INFO] root - Epoch 4 - It. 659: loss = 0.487
2022-01-05 12:54:48,250 [INFO] root - Epoch 4 - It. 679: loss = 0.468
2022-01-05 12:55:31,066 [INFO] root - Epoch 4 - It. 699: loss = 0.476
2022-01-05 12:56:14,400 [INFO] root - Epoch 4 - It. 719: loss = 0.495
2022-01-05 12:56:56,882 [INFO] root - Epoch 4 - It. 739: loss = 0.489
2022-01-05 12:57:38,892 [INFO] root - Epoch 4 - It. 759: loss = 0.472
2022-01-05 12:58:22,220 [INFO] root - Epoch 4 - It. 779: loss = 0.479
2022-01-05 12:58:32,860 [INFO] root - Starting the validation
2022-01-05 12:59:13,964 [INFO] root - VALIDATION -It. 784: total loss: 0.456.
2022-01-05 12:59:13,965 [INFO] root - New best model (loss: 0.4560)
2022-01-05 12:59:13,966 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 12:59:14,427 [INFO] root - Training epoch: 5, LR: [0.0009039207967999998] 
2022-01-05 12:59:47,524 [INFO] root - Epoch 5 - It. 799: loss = 0.453
2022-01-05 13:00:30,319 [INFO] root - Epoch 5 - It. 819: loss = 0.435
2022-01-05 13:01:13,456 [INFO] root - Epoch 5 - It. 839: loss = 0.452
2022-01-05 13:01:56,288 [INFO] root - Epoch 5 - It. 859: loss = 0.427
2022-01-05 13:02:39,618 [INFO] root - Epoch 5 - It. 879: loss = 0.457
2022-01-05 13:03:23,769 [INFO] root - Epoch 5 - It. 899: loss = 0.432
2022-01-05 13:04:07,440 [INFO] root - Epoch 5 - It. 919: loss = 0.458
2022-01-05 13:04:50,655 [INFO] root - Epoch 5 - It. 939: loss = 0.450
2022-01-05 13:04:54,908 [INFO] root - Starting the validation
2022-01-05 13:05:36,522 [INFO] root - VALIDATION -It. 941: total loss: 0.464.
2022-01-05 13:05:36,524 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_941.pt ...
2022-01-05 13:05:36,680 [INFO] root - Training epoch: 6, LR: [0.0008858423808639998] 
2022-01-05 13:06:16,250 [INFO] root - Epoch 6 - It. 959: loss = 0.462
2022-01-05 13:06:59,393 [INFO] root - Epoch 6 - It. 979: loss = 0.401
2022-01-05 13:07:42,313 [INFO] root - Epoch 6 - It. 999: loss = 0.440
2022-01-05 13:08:24,904 [INFO] root - Epoch 6 - It. 1019: loss = 0.406
2022-01-05 13:09:07,684 [INFO] root - Epoch 6 - It. 1039: loss = 0.429
2022-01-05 13:09:51,140 [INFO] root - Epoch 6 - It. 1059: loss = 0.432
2022-01-05 13:10:33,970 [INFO] root - Epoch 6 - It. 1079: loss = 0.416
2022-01-05 13:11:14,924 [INFO] root - Starting the validation
2022-01-05 13:11:56,486 [INFO] root - VALIDATION -It. 1098: total loss: 0.431.
2022-01-05 13:11:56,487 [INFO] root - New best model (loss: 0.4314)
2022-01-05 13:11:56,488 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 13:11:56,956 [INFO] root - Training epoch: 7, LR: [0.0008681255332467198] 
2022-01-05 13:11:59,881 [INFO] root - Epoch 7 - It. 1099: loss = 0.413
2022-01-05 13:12:43,272 [INFO] root - Epoch 7 - It. 1119: loss = 0.399
2022-01-05 13:13:26,532 [INFO] root - Epoch 7 - It. 1139: loss = 0.429
2022-01-05 13:14:09,674 [INFO] root - Epoch 7 - It. 1159: loss = 0.419
2022-01-05 13:14:53,354 [INFO] root - Epoch 7 - It. 1179: loss = 0.414
2022-01-05 13:15:36,215 [INFO] root - Epoch 7 - It. 1199: loss = 0.400
2022-01-05 13:16:19,670 [INFO] root - Epoch 7 - It. 1219: loss = 0.399
2022-01-05 13:17:02,889 [INFO] root - Epoch 7 - It. 1239: loss = 0.387
2022-01-05 13:17:37,591 [INFO] root - Starting the validation
2022-01-05 13:18:18,709 [INFO] root - VALIDATION -It. 1255: total loss: 0.421.
2022-01-05 13:18:18,710 [INFO] root - New best model (loss: 0.4207)
2022-01-05 13:18:18,711 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 13:18:19,180 [INFO] root - Training epoch: 8, LR: [0.0008507630225817853] 
2022-01-05 13:18:28,634 [INFO] root - Epoch 8 - It. 1259: loss = 0.380
2022-01-05 13:19:11,496 [INFO] root - Epoch 8 - It. 1279: loss = 0.399
2022-01-05 13:19:54,858 [INFO] root - Epoch 8 - It. 1299: loss = 0.382
2022-01-05 13:20:38,254 [INFO] root - Epoch 8 - It. 1319: loss = 0.394
2022-01-05 13:21:21,786 [INFO] root - Epoch 8 - It. 1339: loss = 0.386
2022-01-05 13:22:06,294 [INFO] root - Epoch 8 - It. 1359: loss = 0.380
2022-01-05 13:22:50,658 [INFO] root - Epoch 8 - It. 1379: loss = 0.385
2022-01-05 13:23:35,095 [INFO] root - Epoch 8 - It. 1399: loss = 0.380
2022-01-05 13:24:04,097 [INFO] root - Starting the validation
2022-01-05 13:24:46,538 [INFO] root - VALIDATION -It. 1412: total loss: 0.402.
2022-01-05 13:24:46,539 [INFO] root - New best model (loss: 0.4021)
2022-01-05 13:24:46,540 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 13:24:47,023 [INFO] root - Training epoch: 9, LR: [0.0008337477621301496] 
2022-01-05 13:25:03,536 [INFO] root - Epoch 9 - It. 1419: loss = 0.392
2022-01-05 13:25:47,724 [INFO] root - Epoch 9 - It. 1439: loss = 0.375
2022-01-05 13:26:32,235 [INFO] root - Epoch 9 - It. 1459: loss = 0.393
2022-01-05 13:27:16,024 [INFO] root - Epoch 9 - It. 1479: loss = 0.364
2022-01-05 13:28:00,523 [INFO] root - Epoch 9 - It. 1499: loss = 0.362
2022-01-05 13:28:44,250 [INFO] root - Epoch 9 - It. 1519: loss = 0.378
2022-01-05 13:29:28,898 [INFO] root - Epoch 9 - It. 1539: loss = 0.382
2022-01-05 13:30:12,689 [INFO] root - Epoch 9 - It. 1559: loss = 0.372
2022-01-05 13:30:34,650 [INFO] root - Starting the validation
2022-01-05 13:31:17,492 [INFO] root - VALIDATION -It. 1569: total loss: 0.400.
2022-01-05 13:31:17,493 [INFO] root - New best model (loss: 0.3998)
2022-01-05 13:31:17,494 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 13:31:17,980 [INFO] root - Training epoch: 10, LR: [0.0008170728068875465] 
2022-01-05 13:31:40,694 [INFO] root - Epoch 10 - It. 1579: loss = 0.365
2022-01-05 13:32:23,974 [INFO] root - Epoch 10 - It. 1599: loss = 0.349
2022-01-05 13:33:08,178 [INFO] root - Epoch 10 - It. 1619: loss = 0.353
2022-01-05 13:33:52,080 [INFO] root - Epoch 10 - It. 1639: loss = 0.365
2022-01-05 13:34:36,877 [INFO] root - Epoch 10 - It. 1659: loss = 0.355
2022-01-05 13:35:20,511 [INFO] root - Epoch 10 - It. 1679: loss = 0.363
2022-01-05 13:36:03,600 [INFO] root - Epoch 10 - It. 1699: loss = 0.368
2022-01-05 13:36:48,332 [INFO] root - Epoch 10 - It. 1719: loss = 0.362
2022-01-05 13:37:04,150 [INFO] root - Starting the validation
2022-01-05 13:37:46,448 [INFO] root - VALIDATION -It. 1726: total loss: 0.410.
2022-01-05 13:37:46,450 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_1726.pt ...
2022-01-05 13:37:46,625 [INFO] root - Training epoch: 11, LR: [0.0008007313507497956] 
2022-01-05 13:38:16,108 [INFO] root - Epoch 11 - It. 1739: loss = 0.344
2022-01-05 13:39:00,667 [INFO] root - Epoch 11 - It. 1759: loss = 0.317
2022-01-05 13:39:43,847 [INFO] root - Epoch 11 - It. 1779: loss = 0.335
2022-01-05 13:40:27,517 [INFO] root - Epoch 11 - It. 1799: loss = 0.352
2022-01-05 13:41:11,329 [INFO] root - Epoch 11 - It. 1819: loss = 0.366
2022-01-05 13:41:54,393 [INFO] root - Epoch 11 - It. 1839: loss = 0.368
2022-01-05 13:42:37,486 [INFO] root - Epoch 11 - It. 1859: loss = 0.356
2022-01-05 13:43:21,075 [INFO] root - Epoch 11 - It. 1879: loss = 0.326
2022-01-05 13:43:29,997 [INFO] root - Starting the validation
2022-01-05 13:44:12,532 [INFO] root - VALIDATION -It. 1883: total loss: 0.362.
2022-01-05 13:44:12,533 [INFO] root - New best model (loss: 0.3624)
2022-01-05 13:44:12,534 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 13:44:12,988 [INFO] root - Training epoch: 12, LR: [0.0007847167237347997] 
2022-01-05 13:44:48,860 [INFO] root - Epoch 12 - It. 1899: loss = 0.351
2022-01-05 13:45:33,005 [INFO] root - Epoch 12 - It. 1919: loss = 0.335
2022-01-05 13:46:17,095 [INFO] root - Epoch 12 - It. 1939: loss = 0.330
2022-01-05 13:47:01,067 [INFO] root - Epoch 12 - It. 1959: loss = 0.341
2022-01-05 13:47:44,761 [INFO] root - Epoch 12 - It. 1979: loss = 0.317
2022-01-05 13:48:27,538 [INFO] root - Epoch 12 - It. 1999: loss = 0.336
2022-01-05 13:49:11,212 [INFO] root - Epoch 12 - It. 2019: loss = 0.320
2022-01-05 13:49:54,925 [INFO] root - Epoch 12 - It. 2039: loss = 0.317
2022-01-05 13:49:57,027 [INFO] root - Starting the validation
2022-01-05 13:50:39,079 [INFO] root - VALIDATION -It. 2040: total loss: 0.373.
2022-01-05 13:50:39,081 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2040.pt ...
2022-01-05 13:50:39,245 [INFO] root - Training epoch: 13, LR: [0.0007690223892601037] 
2022-01-05 13:51:21,746 [INFO] root - Epoch 13 - It. 2059: loss = 0.321
2022-01-05 13:52:05,647 [INFO] root - Epoch 13 - It. 2079: loss = 0.314
2022-01-05 13:52:49,070 [INFO] root - Epoch 13 - It. 2099: loss = 0.324
2022-01-05 13:53:32,889 [INFO] root - Epoch 13 - It. 2119: loss = 0.332
2022-01-05 13:54:16,239 [INFO] root - Epoch 13 - It. 2139: loss = 0.302
2022-01-05 13:55:00,786 [INFO] root - Epoch 13 - It. 2159: loss = 0.325
2022-01-05 13:55:45,253 [INFO] root - Epoch 13 - It. 2179: loss = 0.340
2022-01-05 13:56:24,297 [INFO] root - Starting the validation
2022-01-05 13:57:06,618 [INFO] root - VALIDATION -It. 2197: total loss: 0.366.
2022-01-05 13:57:06,620 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2197.pt ...
2022-01-05 13:57:06,794 [INFO] root - Training epoch: 14, LR: [0.0007536419414749016] 
2022-01-05 13:57:12,232 [INFO] root - Epoch 14 - It. 2199: loss = 0.345
2022-01-05 13:57:57,063 [INFO] root - Epoch 14 - It. 2219: loss = 0.331
2022-01-05 13:58:41,055 [INFO] root - Epoch 14 - It. 2239: loss = 0.321
2022-01-05 13:59:25,528 [INFO] root - Epoch 14 - It. 2259: loss = 0.311
2022-01-05 14:00:09,821 [INFO] root - Epoch 14 - It. 2279: loss = 0.323
2022-01-05 14:00:53,628 [INFO] root - Epoch 14 - It. 2299: loss = 0.317
2022-01-05 14:01:37,416 [INFO] root - Epoch 14 - It. 2319: loss = 0.298
2022-01-05 14:02:20,635 [INFO] root - Epoch 14 - It. 2339: loss = 0.332
2022-01-05 14:02:52,892 [INFO] root - Starting the validation
2022-01-05 14:03:34,810 [INFO] root - VALIDATION -It. 2354: total loss: 0.357.
2022-01-05 14:03:34,811 [INFO] root - New best model (loss: 0.3568)
2022-01-05 14:03:34,811 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 14:03:35,282 [INFO] root - Training epoch: 15, LR: [0.0007385691026454036] 
2022-01-05 14:03:47,264 [INFO] root - Epoch 15 - It. 2359: loss = 0.290
2022-01-05 14:04:31,577 [INFO] root - Epoch 15 - It. 2379: loss = 0.313
2022-01-05 14:05:15,459 [INFO] root - Epoch 15 - It. 2399: loss = 0.302
2022-01-05 14:05:58,763 [INFO] root - Epoch 15 - It. 2419: loss = 0.312
2022-01-05 14:06:42,149 [INFO] root - Epoch 15 - It. 2439: loss = 0.314
2022-01-05 14:07:26,153 [INFO] root - Epoch 15 - It. 2459: loss = 0.312
2022-01-05 14:08:10,047 [INFO] root - Epoch 15 - It. 2479: loss = 0.294
2022-01-05 14:08:53,670 [INFO] root - Epoch 15 - It. 2499: loss = 0.317
2022-01-05 14:09:19,396 [INFO] root - Starting the validation
2022-01-05 14:10:01,441 [INFO] root - VALIDATION -It. 2511: total loss: 0.354.
2022-01-05 14:10:01,442 [INFO] root - New best model (loss: 0.3541)
2022-01-05 14:10:01,443 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 14:10:01,910 [INFO] root - Training epoch: 16, LR: [0.0007237977205924955] 
2022-01-05 14:10:19,943 [INFO] root - Epoch 16 - It. 2519: loss = 0.312
2022-01-05 14:11:02,468 [INFO] root - Epoch 16 - It. 2539: loss = 0.313
2022-01-05 14:11:44,738 [INFO] root - Epoch 16 - It. 2559: loss = 0.304
2022-01-05 14:12:27,759 [INFO] root - Epoch 16 - It. 2579: loss = 0.312
2022-01-05 14:13:10,686 [INFO] root - Epoch 16 - It. 2599: loss = 0.299
2022-01-05 14:13:53,828 [INFO] root - Epoch 16 - It. 2619: loss = 0.302
2022-01-05 14:14:37,571 [INFO] root - Epoch 16 - It. 2639: loss = 0.284
2022-01-05 14:15:20,420 [INFO] root - Epoch 16 - It. 2659: loss = 0.301
2022-01-05 14:15:40,150 [INFO] root - Starting the validation
2022-01-05 14:16:21,862 [INFO] root - VALIDATION -It. 2668: total loss: 0.335.
2022-01-05 14:16:21,863 [INFO] root - New best model (loss: 0.3346)
2022-01-05 14:16:21,864 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 14:16:22,332 [INFO] root - Training epoch: 17, LR: [0.0007093217661806456] 
2022-01-05 14:16:46,901 [INFO] root - Epoch 17 - It. 2679: loss = 0.300
2022-01-05 14:17:29,430 [INFO] root - Epoch 17 - It. 2699: loss = 0.300
2022-01-05 14:18:13,115 [INFO] root - Epoch 17 - It. 2719: loss = 0.281
2022-01-05 14:18:55,509 [INFO] root - Epoch 17 - It. 2739: loss = 0.308
2022-01-05 14:19:39,332 [INFO] root - Epoch 17 - It. 2759: loss = 0.301
2022-01-05 14:20:22,710 [INFO] root - Epoch 17 - It. 2779: loss = 0.287
2022-01-05 14:21:05,896 [INFO] root - Epoch 17 - It. 2799: loss = 0.275
2022-01-05 14:21:48,086 [INFO] root - Epoch 17 - It. 2819: loss = 0.305
2022-01-05 14:22:00,714 [INFO] root - Starting the validation
2022-01-05 14:22:42,464 [INFO] root - VALIDATION -It. 2825: total loss: 0.350.
2022-01-05 14:22:42,465 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2825.pt ...
2022-01-05 14:22:42,622 [INFO] root - Training epoch: 18, LR: [0.0006951353308570327] 
2022-01-05 14:23:13,840 [INFO] root - Epoch 18 - It. 2839: loss = 0.311
2022-01-05 14:23:56,900 [INFO] root - Epoch 18 - It. 2859: loss = 0.279
2022-01-05 14:24:39,383 [INFO] root - Epoch 18 - It. 2879: loss = 0.285
2022-01-05 14:25:22,845 [INFO] root - Epoch 18 - It. 2899: loss = 0.285
2022-01-05 14:26:06,675 [INFO] root - Epoch 18 - It. 2919: loss = 0.296
2022-01-05 14:26:50,077 [INFO] root - Epoch 18 - It. 2939: loss = 0.297
2022-01-05 14:27:33,602 [INFO] root - Epoch 18 - It. 2959: loss = 0.282
2022-01-05 14:28:16,312 [INFO] root - Epoch 18 - It. 2979: loss = 0.296
2022-01-05 14:28:22,873 [INFO] root - Starting the validation
2022-01-05 14:29:04,733 [INFO] root - VALIDATION -It. 2982: total loss: 0.348.
2022-01-05 14:29:04,734 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_2982.pt ...
2022-01-05 14:29:04,891 [INFO] root - Training epoch: 19, LR: [0.000681232624239892] 
2022-01-05 14:29:42,454 [INFO] root - Epoch 19 - It. 2999: loss = 0.282
2022-01-05 14:30:25,339 [INFO] root - Epoch 19 - It. 3019: loss = 0.278
2022-01-05 14:31:08,624 [INFO] root - Epoch 19 - It. 3039: loss = 0.265
2022-01-05 14:31:51,623 [INFO] root - Epoch 19 - It. 3059: loss = 0.295
2022-01-05 14:32:35,227 [INFO] root - Epoch 19 - It. 3079: loss = 0.287
2022-01-05 14:33:18,666 [INFO] root - Epoch 19 - It. 3099: loss = 0.288
2022-01-05 14:34:02,867 [INFO] root - Epoch 19 - It. 3119: loss = 0.292
2022-01-05 14:34:47,299 [INFO] root - Epoch 19 - It. 3139: loss = 0.275
2022-01-05 14:34:47,302 [INFO] root - Starting the validation
2022-01-05 14:35:29,617 [INFO] root - VALIDATION -It. 3139: total loss: 0.347.
2022-01-05 14:35:29,618 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3139.pt ...
2022-01-05 14:35:29,782 [INFO] root - Training epoch: 20, LR: [0.0006676079717550942] 
2022-01-05 14:36:14,895 [INFO] root - Epoch 20 - It. 3159: loss = 0.280
2022-01-05 14:36:58,899 [INFO] root - Epoch 20 - It. 3179: loss = 0.281
2022-01-05 14:37:42,819 [INFO] root - Epoch 20 - It. 3199: loss = 0.292
2022-01-05 14:38:26,855 [INFO] root - Epoch 20 - It. 3219: loss = 0.310
2022-01-05 14:39:11,303 [INFO] root - Epoch 20 - It. 3239: loss = 0.307
2022-01-05 14:39:55,698 [INFO] root - Epoch 20 - It. 3259: loss = 0.273
2022-01-05 14:40:39,558 [INFO] root - Epoch 20 - It. 3279: loss = 0.280
2022-01-05 14:41:16,718 [INFO] root - Starting the validation
2022-01-05 14:41:59,166 [INFO] root - VALIDATION -It. 3296: total loss: 0.338.
2022-01-05 14:41:59,168 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3296.pt ...
2022-01-05 14:41:59,333 [INFO] root - Training epoch: 21, LR: [0.0006542558123199924] 
2022-01-05 14:42:06,570 [INFO] root - Epoch 21 - It. 3299: loss = 0.277
2022-01-05 14:42:50,390 [INFO] root - Epoch 21 - It. 3319: loss = 0.274
2022-01-05 14:43:34,416 [INFO] root - Epoch 21 - It. 3339: loss = 0.283
2022-01-05 14:44:19,256 [INFO] root - Epoch 21 - It. 3359: loss = 0.297
2022-01-05 14:45:02,804 [INFO] root - Epoch 21 - It. 3379: loss = 0.269
2022-01-05 14:45:46,725 [INFO] root - Epoch 21 - It. 3399: loss = 0.273
2022-01-05 14:46:30,975 [INFO] root - Epoch 21 - It. 3419: loss = 0.268
2022-01-05 14:47:14,828 [INFO] root - Epoch 21 - It. 3439: loss = 0.281
2022-01-05 14:47:45,543 [INFO] root - Starting the validation
2022-01-05 14:48:28,479 [INFO] root - VALIDATION -It. 3453: total loss: 0.325.
2022-01-05 14:48:28,480 [INFO] root - New best model (loss: 0.3246)
2022-01-05 14:48:28,481 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 14:48:28,961 [INFO] root - Training epoch: 22, LR: [0.0006411706960735925] 
2022-01-05 14:48:43,218 [INFO] root - Epoch 22 - It. 3459: loss = 0.274
2022-01-05 14:49:27,135 [INFO] root - Epoch 22 - It. 3479: loss = 0.259
2022-01-05 14:50:11,594 [INFO] root - Epoch 22 - It. 3499: loss = 0.255
2022-01-05 14:50:55,577 [INFO] root - Epoch 22 - It. 3519: loss = 0.262
2022-01-05 14:51:38,826 [INFO] root - Epoch 22 - It. 3539: loss = 0.255
2022-01-05 14:52:22,697 [INFO] root - Epoch 22 - It. 3559: loss = 0.270
2022-01-05 14:53:06,572 [INFO] root - Epoch 22 - It. 3579: loss = 0.268
2022-01-05 14:53:50,425 [INFO] root - Epoch 22 - It. 3599: loss = 0.281
2022-01-05 14:54:14,781 [INFO] root - Starting the validation
2022-01-05 14:54:57,932 [INFO] root - VALIDATION -It. 3610: total loss: 0.336.
2022-01-05 14:54:57,933 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3610.pt ...
2022-01-05 14:54:58,095 [INFO] root - Training epoch: 23, LR: [0.0006283472821521206] 
2022-01-05 14:55:19,071 [INFO] root - Epoch 23 - It. 3619: loss = 0.264
2022-01-05 14:56:02,387 [INFO] root - Epoch 23 - It. 3639: loss = 0.244
2022-01-05 14:56:46,370 [INFO] root - Epoch 23 - It. 3659: loss = 0.254
2022-01-05 14:57:29,687 [INFO] root - Epoch 23 - It. 3679: loss = 0.263
2022-01-05 14:58:12,953 [INFO] root - Epoch 23 - It. 3699: loss = 0.267
2022-01-05 14:58:57,243 [INFO] root - Epoch 23 - It. 3719: loss = 0.264
2022-01-05 14:59:40,815 [INFO] root - Epoch 23 - It. 3739: loss = 0.257
2022-01-05 15:00:24,543 [INFO] root - Epoch 23 - It. 3759: loss = 0.275
2022-01-05 15:00:42,424 [INFO] root - Starting the validation
2022-01-05 15:01:25,349 [INFO] root - VALIDATION -It. 3767: total loss: 0.319.
2022-01-05 15:01:25,350 [INFO] root - New best model (loss: 0.3191)
2022-01-05 15:01:25,351 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 15:01:25,830 [INFO] root - Training epoch: 24, LR: [0.0006157803365090782] 
2022-01-05 15:01:53,599 [INFO] root - Epoch 24 - It. 3779: loss = 0.260
2022-01-05 15:02:38,320 [INFO] root - Epoch 24 - It. 3799: loss = 0.255
2022-01-05 15:03:23,987 [INFO] root - Epoch 24 - It. 3819: loss = 0.242
2022-01-05 15:04:08,783 [INFO] root - Epoch 24 - It. 3839: loss = 0.276
2022-01-05 15:04:54,157 [INFO] root - Epoch 24 - It. 3859: loss = 0.250
2022-01-05 15:05:39,120 [INFO] root - Epoch 24 - It. 3879: loss = 0.261
2022-01-05 15:06:24,321 [INFO] root - Epoch 24 - It. 3899: loss = 0.250
2022-01-05 15:07:08,974 [INFO] root - Epoch 24 - It. 3919: loss = 0.254
2022-01-05 15:07:20,259 [INFO] root - Starting the validation
2022-01-05 15:08:04,362 [INFO] root - VALIDATION -It. 3924: total loss: 0.329.
2022-01-05 15:08:04,364 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_3924.pt ...
2022-01-05 15:08:04,550 [INFO] root - Training epoch: 25, LR: [0.0006034647297788967] 
2022-01-05 15:08:39,148 [INFO] root - Epoch 25 - It. 3939: loss = 0.260
2022-01-05 15:09:24,141 [INFO] root - Epoch 25 - It. 3959: loss = 0.262
2022-01-05 15:10:09,263 [INFO] root - Epoch 25 - It. 3979: loss = 0.245
2022-01-05 15:10:54,856 [INFO] root - Epoch 25 - It. 3999: loss = 0.264
2022-01-05 15:11:40,213 [INFO] root - Epoch 25 - It. 4019: loss = 0.264
2022-01-05 15:12:25,830 [INFO] root - Epoch 25 - It. 4039: loss = 0.251
2022-01-05 15:13:10,896 [INFO] root - Epoch 25 - It. 4059: loss = 0.256
2022-01-05 15:13:55,782 [INFO] root - Epoch 25 - It. 4079: loss = 0.261
2022-01-05 15:14:00,192 [INFO] root - Starting the validation
2022-01-05 15:14:44,377 [INFO] root - VALIDATION -It. 4081: total loss: 0.313.
2022-01-05 15:14:44,378 [INFO] root - New best model (loss: 0.3134)
2022-01-05 15:14:44,379 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 15:14:44,862 [INFO] root - Training epoch: 26, LR: [0.0005913954351833187] 
2022-01-05 15:15:26,692 [INFO] root - Epoch 26 - It. 4099: loss = 0.259
2022-01-05 15:16:11,265 [INFO] root - Epoch 26 - It. 4119: loss = 0.259
2022-01-05 15:16:56,993 [INFO] root - Epoch 26 - It. 4139: loss = 0.247
2022-01-05 15:17:41,772 [INFO] root - Epoch 26 - It. 4159: loss = 0.261
2022-01-05 15:18:26,757 [INFO] root - Epoch 26 - It. 4179: loss = 0.261
2022-01-05 15:19:11,975 [INFO] root - Epoch 26 - It. 4199: loss = 0.251
2022-01-05 15:19:56,648 [INFO] root - Epoch 26 - It. 4219: loss = 0.267
2022-01-05 15:20:39,487 [INFO] root - Starting the validation
2022-01-05 15:21:23,784 [INFO] root - VALIDATION -It. 4238: total loss: 0.310.
2022-01-05 15:21:23,785 [INFO] root - New best model (loss: 0.3103)
2022-01-05 15:21:23,786 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 15:21:24,279 [INFO] root - Training epoch: 27, LR: [0.0005795675264796523] 
2022-01-05 15:21:27,714 [INFO] root - Epoch 27 - It. 4239: loss = 0.267
2022-01-05 15:22:13,121 [INFO] root - Epoch 27 - It. 4259: loss = 0.255
2022-01-05 15:22:58,310 [INFO] root - Epoch 27 - It. 4279: loss = 0.241
2022-01-05 15:23:43,099 [INFO] root - Epoch 27 - It. 4299: loss = 0.257
2022-01-05 15:24:28,353 [INFO] root - Epoch 27 - It. 4319: loss = 0.238
2022-01-05 15:25:13,606 [INFO] root - Epoch 27 - It. 4339: loss = 0.253
2022-01-05 15:25:58,573 [INFO] root - Epoch 27 - It. 4359: loss = 0.257
2022-01-05 15:26:43,376 [INFO] root - Epoch 27 - It. 4379: loss = 0.263
2022-01-05 15:27:19,180 [INFO] root - Starting the validation
2022-01-05 15:28:02,810 [INFO] root - VALIDATION -It. 4395: total loss: 0.306.
2022-01-05 15:28:02,812 [INFO] root - New best model (loss: 0.3055)
2022-01-05 15:28:02,813 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 15:28:03,297 [INFO] root - Training epoch: 28, LR: [0.0005679761759500593] 
2022-01-05 15:28:13,535 [INFO] root - Epoch 28 - It. 4399: loss = 0.241
2022-01-05 15:28:59,329 [INFO] root - Epoch 28 - It. 4419: loss = 0.237
2022-01-05 15:29:43,656 [INFO] root - Epoch 28 - It. 4439: loss = 0.263
2022-01-05 15:30:29,111 [INFO] root - Epoch 28 - It. 4459: loss = 0.234
2022-01-05 15:31:14,074 [INFO] root - Epoch 28 - It. 4479: loss = 0.284
2022-01-05 15:31:58,437 [INFO] root - Epoch 28 - It. 4499: loss = 0.278
2022-01-05 15:32:43,922 [INFO] root - Epoch 28 - It. 4519: loss = 0.256
2022-01-05 15:33:29,584 [INFO] root - Epoch 28 - It. 4539: loss = 0.253
2022-01-05 15:33:58,760 [INFO] root - Starting the validation
2022-01-05 15:34:42,671 [INFO] root - VALIDATION -It. 4552: total loss: 0.316.
2022-01-05 15:34:42,673 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4552.pt ...
2022-01-05 15:34:42,851 [INFO] root - Training epoch: 29, LR: [0.0005566166524310581] 
2022-01-05 15:34:59,954 [INFO] root - Epoch 29 - It. 4559: loss = 0.245
2022-01-05 15:35:45,226 [INFO] root - Epoch 29 - It. 4579: loss = 0.253
2022-01-05 15:36:30,332 [INFO] root - Epoch 29 - It. 4599: loss = 0.257
2022-01-05 15:37:15,990 [INFO] root - Epoch 29 - It. 4619: loss = 0.241
2022-01-05 15:38:00,672 [INFO] root - Epoch 29 - It. 4639: loss = 0.249
2022-01-05 15:38:45,494 [INFO] root - Epoch 29 - It. 4659: loss = 0.252
2022-01-05 15:39:29,974 [INFO] root - Epoch 29 - It. 4679: loss = 0.249
2022-01-05 15:40:15,704 [INFO] root - Epoch 29 - It. 4699: loss = 0.245
2022-01-05 15:40:37,869 [INFO] root - Starting the validation
2022-01-05 15:41:21,955 [INFO] root - VALIDATION -It. 4709: total loss: 0.319.
2022-01-05 15:41:21,956 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4709.pt ...
2022-01-05 15:41:22,131 [INFO] root - Training epoch: 30, LR: [0.0005454843193824369] 
2022-01-05 15:41:45,335 [INFO] root - Epoch 30 - It. 4719: loss = 0.243
2022-01-05 15:42:30,823 [INFO] root - Epoch 30 - It. 4739: loss = 0.229
2022-01-05 15:43:15,783 [INFO] root - Epoch 30 - It. 4759: loss = 0.245
2022-01-05 15:44:00,470 [INFO] root - Epoch 30 - It. 4779: loss = 0.251
2022-01-05 15:44:46,144 [INFO] root - Epoch 30 - It. 4799: loss = 0.226
2022-01-05 15:45:31,764 [INFO] root - Epoch 30 - It. 4819: loss = 0.229
2022-01-05 15:46:16,165 [INFO] root - Epoch 30 - It. 4839: loss = 0.245
2022-01-05 15:46:59,795 [INFO] root - Epoch 30 - It. 4859: loss = 0.266
2022-01-05 15:47:16,018 [INFO] root - Starting the validation
2022-01-05 15:47:59,893 [INFO] root - VALIDATION -It. 4866: total loss: 0.325.
2022-01-05 15:47:59,894 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_4866.pt ...
2022-01-05 15:48:00,077 [INFO] root - Training epoch: 31, LR: [0.0005345746329947881] 
2022-01-05 15:48:30,966 [INFO] root - Epoch 31 - It. 4879: loss = 0.247
2022-01-05 15:49:16,313 [INFO] root - Epoch 31 - It. 4899: loss = 0.232
2022-01-05 15:50:01,650 [INFO] root - Epoch 31 - It. 4919: loss = 0.243
2022-01-05 15:50:46,860 [INFO] root - Epoch 31 - It. 4939: loss = 0.254
2022-01-05 15:51:31,742 [INFO] root - Epoch 31 - It. 4959: loss = 0.231
2022-01-05 15:52:16,567 [INFO] root - Epoch 31 - It. 4979: loss = 0.244
2022-01-05 15:53:01,382 [INFO] root - Epoch 31 - It. 4999: loss = 0.252
2022-01-05 15:53:47,105 [INFO] root - Epoch 31 - It. 5019: loss = 0.245
2022-01-05 15:53:56,274 [INFO] root - Starting the validation
2022-01-05 15:54:40,545 [INFO] root - VALIDATION -It. 5023: total loss: 0.334.
2022-01-05 15:54:40,547 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5023.pt ...
2022-01-05 15:54:40,729 [INFO] root - Training epoch: 32, LR: [0.0005238831403348923] 
2022-01-05 15:55:17,538 [INFO] root - Epoch 32 - It. 5039: loss = 0.266
2022-01-05 15:56:02,225 [INFO] root - Epoch 32 - It. 5059: loss = 0.234
2022-01-05 15:56:47,842 [INFO] root - Epoch 32 - It. 5079: loss = 0.236
2022-01-05 15:57:33,498 [INFO] root - Epoch 32 - It. 5099: loss = 0.230
2022-01-05 15:58:18,536 [INFO] root - Epoch 32 - It. 5119: loss = 0.244
2022-01-05 15:59:03,186 [INFO] root - Epoch 32 - It. 5139: loss = 0.239
2022-01-05 15:59:48,283 [INFO] root - Epoch 32 - It. 5159: loss = 0.241
2022-01-05 16:00:33,524 [INFO] root - Epoch 32 - It. 5179: loss = 0.242
2022-01-05 16:00:35,441 [INFO] root - Starting the validation
2022-01-05 16:01:19,968 [INFO] root - VALIDATION -It. 5180: total loss: 0.323.
2022-01-05 16:01:19,970 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5180.pt ...
2022-01-05 16:01:20,148 [INFO] root - Training epoch: 33, LR: [0.0005134054775281945] 
2022-01-05 16:02:03,932 [INFO] root - Epoch 33 - It. 5199: loss = 0.246
2022-01-05 16:02:50,168 [INFO] root - Epoch 33 - It. 5219: loss = 0.236
2022-01-05 16:03:34,737 [INFO] root - Epoch 33 - It. 5239: loss = 0.238
2022-01-05 16:04:20,287 [INFO] root - Epoch 33 - It. 5259: loss = 0.238
2022-01-05 16:05:04,621 [INFO] root - Epoch 33 - It. 5279: loss = 0.241
2022-01-05 16:05:49,597 [INFO] root - Epoch 33 - It. 5299: loss = 0.229
2022-01-05 16:06:35,093 [INFO] root - Epoch 33 - It. 5319: loss = 0.241
2022-01-05 16:07:15,080 [INFO] root - Starting the validation
2022-01-05 16:07:59,265 [INFO] root - VALIDATION -It. 5337: total loss: 0.328.
2022-01-05 16:07:59,267 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5337.pt ...
2022-01-05 16:07:59,441 [INFO] root - Training epoch: 34, LR: [0.0005031373679776305] 
2022-01-05 16:08:04,812 [INFO] root - Epoch 34 - It. 5339: loss = 0.243
2022-01-05 16:08:50,183 [INFO] root - Epoch 34 - It. 5359: loss = 0.234
2022-01-05 16:09:34,719 [INFO] root - Epoch 34 - It. 5379: loss = 0.231
2022-01-05 16:10:20,601 [INFO] root - Epoch 34 - It. 5399: loss = 0.237
2022-01-05 16:11:05,073 [INFO] root - Epoch 34 - It. 5419: loss = 0.238
2022-01-05 16:11:50,958 [INFO] root - Epoch 34 - It. 5439: loss = 0.228
2022-01-05 16:12:36,347 [INFO] root - Epoch 34 - It. 5459: loss = 0.238
2022-01-05 16:13:20,816 [INFO] root - Epoch 34 - It. 5479: loss = 0.241
2022-01-05 16:13:55,237 [INFO] root - Starting the validation
2022-01-05 16:14:39,547 [INFO] root - VALIDATION -It. 5494: total loss: 0.315.
2022-01-05 16:14:39,549 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5494.pt ...
2022-01-05 16:14:39,733 [INFO] root - Training epoch: 35, LR: [0.0004930746206180779] 
2022-01-05 16:14:52,310 [INFO] root - Epoch 35 - It. 5499: loss = 0.221
2022-01-05 16:15:36,499 [INFO] root - Epoch 35 - It. 5519: loss = 0.221
2022-01-05 16:16:21,762 [INFO] root - Epoch 35 - It. 5539: loss = 0.232
2022-01-05 16:17:07,593 [INFO] root - Epoch 35 - It. 5559: loss = 0.218
2022-01-05 16:17:53,523 [INFO] root - Epoch 35 - It. 5579: loss = 0.246
2022-01-05 16:18:39,795 [INFO] root - Epoch 35 - It. 5599: loss = 0.237
2022-01-05 16:19:25,177 [INFO] root - Epoch 35 - It. 5619: loss = 0.214
2022-01-05 16:20:10,572 [INFO] root - Epoch 35 - It. 5639: loss = 0.221
2022-01-05 16:20:37,816 [INFO] root - Starting the validation
2022-01-05 16:21:22,881 [INFO] root - VALIDATION -It. 5651: total loss: 0.308.
2022-01-05 16:21:22,883 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5651.pt ...
2022-01-05 16:21:23,070 [INFO] root - Training epoch: 36, LR: [0.00048321312820571636] 
2022-01-05 16:21:42,575 [INFO] root - Epoch 36 - It. 5659: loss = 0.221
2022-01-05 16:22:28,753 [INFO] root - Epoch 36 - It. 5679: loss = 0.223
2022-01-05 16:23:13,866 [INFO] root - Epoch 36 - It. 5699: loss = 0.225
2022-01-05 16:23:58,871 [INFO] root - Epoch 36 - It. 5719: loss = 0.225
2022-01-05 16:24:44,464 [INFO] root - Epoch 36 - It. 5739: loss = 0.243
2022-01-05 16:25:30,299 [INFO] root - Epoch 36 - It. 5759: loss = 0.228
2022-01-05 16:26:16,484 [INFO] root - Epoch 36 - It. 5779: loss = 0.223
2022-01-05 16:27:01,711 [INFO] root - Epoch 36 - It. 5799: loss = 0.234
2022-01-05 16:27:22,561 [INFO] root - Starting the validation
2022-01-05 16:28:07,911 [INFO] root - VALIDATION -It. 5808: total loss: 0.307.
2022-01-05 16:28:07,913 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5808.pt ...
2022-01-05 16:28:08,105 [INFO] root - Training epoch: 37, LR: [0.00047354886564160203] 
2022-01-05 16:28:34,751 [INFO] root - Epoch 37 - It. 5819: loss = 0.231
2022-01-05 16:29:20,263 [INFO] root - Epoch 37 - It. 5839: loss = 0.220
2022-01-05 16:30:05,520 [INFO] root - Epoch 37 - It. 5859: loss = 0.227
2022-01-05 16:30:50,885 [INFO] root - Epoch 37 - It. 5879: loss = 0.231
2022-01-05 16:31:35,314 [INFO] root - Epoch 37 - It. 5899: loss = 0.222
2022-01-05 16:32:21,066 [INFO] root - Epoch 37 - It. 5919: loss = 0.219
2022-01-05 16:33:06,905 [INFO] root - Epoch 37 - It. 5939: loss = 0.222
2022-01-05 16:33:52,039 [INFO] root - Epoch 37 - It. 5959: loss = 0.236
2022-01-05 16:34:05,763 [INFO] root - Starting the validation
2022-01-05 16:34:50,804 [INFO] root - VALIDATION -It. 5965: total loss: 0.312.
2022-01-05 16:34:50,806 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_5965.pt ...
2022-01-05 16:34:50,988 [INFO] root - Training epoch: 38, LR: [0.00046407788832877] 
2022-01-05 16:35:24,075 [INFO] root - Epoch 38 - It. 5979: loss = 0.222
2022-01-05 16:36:10,073 [INFO] root - Epoch 38 - It. 5999: loss = 0.217
2022-01-05 16:36:54,836 [INFO] root - Epoch 38 - It. 6019: loss = 0.216
2022-01-05 16:37:39,766 [INFO] root - Epoch 38 - It. 6039: loss = 0.226
2022-01-05 16:38:24,347 [INFO] root - Epoch 38 - It. 6059: loss = 0.221
2022-01-05 16:39:10,047 [INFO] root - Epoch 38 - It. 6079: loss = 0.233
2022-01-05 16:39:56,190 [INFO] root - Epoch 38 - It. 6099: loss = 0.217
2022-01-05 16:40:42,953 [INFO] root - Epoch 38 - It. 6119: loss = 0.240
2022-01-05 16:40:50,063 [INFO] root - Starting the validation
2022-01-05 16:41:35,540 [INFO] root - VALIDATION -It. 6122: total loss: 0.314.
2022-01-05 16:41:35,542 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_6122.pt ...
2022-01-05 16:41:35,735 [INFO] root - Training epoch: 39, LR: [0.0004547963305621946] 
2022-01-05 16:42:16,689 [INFO] root - Epoch 39 - It. 6139: loss = 0.216
2022-01-05 16:43:02,486 [INFO] root - Epoch 39 - It. 6159: loss = 0.210
2022-01-05 16:43:47,907 [INFO] root - Epoch 39 - It. 6179: loss = 0.241
2022-01-05 16:44:34,160 [INFO] root - Epoch 39 - It. 6199: loss = 0.229
2022-01-05 16:45:19,833 [INFO] root - Epoch 39 - It. 6219: loss = 0.217
2022-01-05 16:46:05,024 [INFO] root - Epoch 39 - It. 6239: loss = 0.216
2022-01-05 16:46:50,322 [INFO] root - Epoch 39 - It. 6259: loss = 0.224
2022-01-05 16:47:34,988 [INFO] root - Epoch 39 - It. 6279: loss = 0.224
2022-01-05 16:47:34,991 [INFO] root - Starting the validation
2022-01-05 16:48:19,470 [INFO] root - VALIDATION -It. 6279: total loss: 0.291.
2022-01-05 16:48:19,471 [INFO] root - New best model (loss: 0.2914)
2022-01-05 16:48:19,472 [INFO] root - Saving checkpoint: ./logs/logs_SemanticKITTI_ME/22_01_05-12_27_39_743342__Method_ME__Flow___Ego___Sem___Rem_Ground___VoxSize_0.1__Pts_8192/model_best.pt ...
2022-01-05 16:48:19,963 [INFO] root - Training completed after 39 Epochs (156 it) with best val metric (total_loss)=0.29137641191482544
